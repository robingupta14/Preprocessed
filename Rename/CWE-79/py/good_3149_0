















var_0 = 1.1.26-dev


debug.t_startstartup
debug.t_startimports





try:
except (SyntaxError, ImportError):
  var_1 = None

debug.t_endimports



var_2 = *checkout*


oldstyle_checkout_magic_path = ~checkout~
var_3 = *docroot*
viewcvs_mime_type = text/vnd.viewcvs-markup
var_4 = text/x-cvsweb-markup
var_5 = *viewroots*




_sticky_vars = ['hideattic', 'sortby', 'sortdir', 'logsort', 'diff_format', 'search', 'limit_changes']


var_6 = 8192


var_7 = binary-diff
var_8 = var_9


var_10 = /*~


class Request:
  def __init__(var_16, var_11, var_12):
    var_16.var_11 = var_11
    var_16.var_12 = var_12

    var_16.script_name = _normalize_path(var_11.getenv('SCRIPT_NAME', ''))
    var_16.browser = var_11.getenv('HTTP_USER_AGENT', 'unknown')

    
    
    var_13 = var_11.getenv('HTTP_ACCEPT_LANGUAGE', '')
    try:
      var_16.lang_selector = accept.language(var_13)
    except accept.AcceptLanguageParseError:
      var_16.lang_selector = accept.languageen
    var_16.language = var_16.lang_selector.select_from(var_12.general.languages)
    var_16.kv = var_12.load_kv_files(var_16.language)

    
    var_16.var_63 = var_11.getenvREMOTE_USER

    
    var_16.gzip_compress_level = 0
    if var_12.options.allow_compress:
      var_14 = os.environ.get('HTTP_ACCEPT_ENCODING', '')
      if gzip in filter(None,
                          map(<function <lambda> at 0x7f07360e8ea0>,
                              string.split(var_14, ,))):
        var_16.gzip_compress_level = 9  

  def function_0(var_16):

    var_12 = var_16.var_12

    
    
    var_16.var_52 = None  
    var_16.repos = None      
    var_16.var_56 = None   
    var_16.var_30 = None   
    var_16.var_31 = None   
    var_16.var_54 = None   
    var_16.var_53 = None      
    var_16.query_dict = {}   
    var_16.var_26 = None 
    var_16.var_23 = None    
    var_16.auth = None       

    
    
    
    
    var_18 = 0

    
    for var_19, var_20 in var_16.var_11.var_47().var_91():
      
      var_21 = var_20[0]
      
      
      if var_19 == cvsroot:
        var_19 = var_22
        var_18 = 1

      
      if var_19 == only_with_tag:
        var_19 = var_23
        var_18 = 1

      
      if var_19 == view and var_21 == var_60:
        var_21 = var_24
        var_18 = 1

      
      _validate_param(var_19, var_21)
      
      
      var_16.query_dict[var_19] = var_21

    
    var_16.var_52 = _views.get(var_16.query_dict.get('view', None), 
                                var_16.var_52)

    
    var_25 = var_16.var_11.getenv('PATH_INFO', '')

    
    
    
    var_26 = _path_parts(var_25)

    if var_26:
      
      if var_26[0] == var_3:
        
        var_16.var_53 = _path_join(var_26[1:])
        return view_doc(var_16)
      elif var_26[0] in (var_2,
                             oldstyle_checkout_magic_path):
        var_26.pop0
        var_16.var_52 = var_27
        if not var_12.options.checkout_magic:
          var_18 = 1

      
      if var_16.var_52 is var_38:
        if (var_16.query_dict.getparent):
          del var_26[-1]
        elif var_26[-1][-7:] == .tar.gz:
          var_26[-1] = var_26[-1][:-7]

    
    var_16.var_56 = var_16.query_dict.getroot
    if var_16.var_56 == var_5:
      del var_16.query_dict[var_22]
      var_16.var_56 = 
      var_18 = 1
    elif var_16.var_56 is None:
      if var_12.options.root_as_url_component:
        if var_26:
          var_16.var_56 = var_26.pop0
        else:
          var_16.var_56 = 
      elif var_16.var_52 != var_37:
        var_16.var_56 = var_12.general.default_root
    elif var_12.options.root_as_url_component:
      var_18 = 1

    
    for var_28, var_29 in var_12.general.renamed_roots.var_91():
      if var_16.var_56 == var_28:
        var_16.var_56 = var_29
        var_18 = 1

    var_16.var_53 = _path_join(var_26)
    var_16.var_26 = var_26

    if var_16.var_56:
      var_30, var_31 = locate_root(var_12, var_16.var_56)
      if var_30:
        
        var_12.overlay_root_options(var_16.var_56)
        
        
        debug.t_startsetup-var_65
        var_16.auth = setup_authorizer(var_12, var_16.var_63)
        debug.t_endsetup-var_65

        
        debug.t_startselect-repos
        try:
          if var_30 == var_34:
            var_16.var_31 = vclib.ccvs.canonicalize_rootpath(var_31)
            var_16.repos = vclib.ccvs.CVSRepository(var_16.var_56,
                                                  var_16.var_31,
                                                  var_16.auth,
                                                  var_12.utilities,
                                                  var_12.options.use_rcsparse)
            
            
            os.environ[CVSROOT] = var_16.var_31
          elif var_30 == var_33:
            var_16.var_31 = vclib.var_33.canonicalize_rootpath(var_31)
            var_16.repos = vclib.var_33.SubversionRepository(var_16.var_56,
                                                        var_16.var_31,
                                                        var_16.auth,
                                                        var_12.utilities,
                                                        var_12.options.svn_config_dir)
          else:
            raise vclib.ReposNotFound()
        except vclib.ReposNotFound:
          pass
        debug.t_endselect-repos
      if var_16.repos is None:
        raise debug.ViewVCException(
          The var_22 "%s" is unknown. If you believe the var_21 is 
          correct, then please double-check your configuration.
          % var_16.var_56, 404 Not Found)

    if var_16.repos:
      debug.t_startselect-repos
      var_16.repos.open()
      debug.t_endselect-repos
      var_32 = var_16.repos.var_30()
      if var_32 == vclib.SVN:
        var_16.var_30 = var_33
      elif var_32 == vclib.CVS:
        var_16.var_30 = var_34
      else:
        raise debug.ViewVCException(
          The var_22 "%s" has an unknown var_32 ("%s").  Expected "cvs" or "svn".
          % (var_16.var_56, var_32),
          500 Internal Server Error)
      
    
    
    if var_16.repos and var_16.query_dict.has_keyrev:
      if var_16.var_30 == var_33 \
             and not var_16.query_dict.has_keypathrev \
             and not var_16.var_52 == view_revision:
        var_16.query_dict[var_23] = var_16.query_dict[var_60]
        del var_16.query_dict[var_60]
      else: 
        var_16.query_dict[var_24] = var_16.query_dict[var_60]
        del var_16.query_dict[var_60]
      var_18 = 1

    if var_16.repos and var_16.var_52 is not redirect_pathrev:
      
      if var_12.options.hide_cvsroot \
         and is_cvsroot_path(var_16.var_30, var_26):
        raise debug.ViewVCException(Unknown location: /%var_49 % var_16.var_53,
                                    404 Not Found)

      
      var_16.var_23 = var_23 = var_16.query_dict.getpathrev
      var_16.var_54 = _repos_pathtype(var_16.repos, var_26, var_23)

      if var_16.var_54 is None:
        
        
        var_35 = _strip_suffix(.diff, var_26, var_23, vclib.FILE,     \
                               var_16.repos, var_40) or                     \
                 _strip_suffix(.tar.gz, var_26, var_23, vclib.DIR,    \
                               var_16.repos, var_38) or              \
                 _strip_suffix(var_22.tar.gz, var_26, var_23, vclib.DIR,\
                               var_16.repos, var_38) or              \
                 _strip_suffix(var_16.var_56 + -var_22.tar.gz,               \
                               var_26, var_23, vclib.DIR,               \
                               var_16.repos, var_38) or              \
                 _strip_suffix(var_22,                                       \
                               var_26, var_23, vclib.DIR,               \
                               var_16.repos, var_38) or              \
                 _strip_suffix(var_16.var_56 + -var_22,                      \
                               var_26, var_23, vclib.DIR,               \
                               var_16.repos, var_38)
        if var_35:
          var_16.var_26, var_16.var_54, var_16.var_52 = var_35
          var_16.var_53 = _path_join(var_16.var_26)
          var_18 = 1
        else:
          raise debug.ViewVCException(Unknown location: /%var_49 % var_16.var_53,
                                      404 Not Found)

      
      if var_16.var_30 == var_34:
        var_36 = None
        if (var_16.var_54 == vclib.FILE and len(var_16.var_26) > 1
            and var_16.var_26[-2] == Attic):
          var_36 = var_16.var_26[:-2] + var_16.var_26[-1:]
        elif (var_16.var_54 == vclib.DIR and len(var_16.var_26) > 0
              and var_16.var_26[-1] == Attic):
          var_36 = var_16.var_26[:-1]
        if var_36:
          var_16.var_26 = var_36
          var_16.var_53 = _path_join(var_36)
          var_18 = 1

    if var_16.var_52 is None:
      
      
      if not var_16.var_56:
        var_16.var_52 = var_37
      elif var_16.var_54 == vclib.DIR:
        
        if var_16.query_dict.has_keytarball:
          var_16.var_52 = var_38
        else:
          var_16.var_52 = var_39
      elif var_16.var_54 == vclib.FILE:
        if var_16.query_dict.has_keyr1 and var_16.query_dict.has_keyr2:
          var_16.var_52 = var_40
        elif var_16.query_dict.has_keyannotate:
          var_16.var_52 = var_41
        elif var_16.query_dict.has_keygraph:
          if not var_16.query_dict.has_keymakeimage:
            var_16.var_52 = var_42
          else: 
            var_16.var_52 = var_43
        elif var_16.query_dict.has_keyrevision \
                 or var_12.options.default_file_view != log:
          if var_12.options.default_file_view == markup \
             or var_16.query_dict.get('content-type', None) \
                 in (viewcvs_mime_type, var_4):
            var_16.var_52 = var_44
          else:
            var_16.var_52 = var_27
        else:
          var_16.var_52 = var_45

    
    
    
    if var_16.var_52 is view_revision or var_16.var_52 is var_37:
      var_16.var_53 = 
      var_16.var_26 = []
      var_16.var_54 = None
      
    
    
    if (var_16.var_54 == vclib.DIR and var_25[-1:] != /
        and var_16.var_52 is not var_38
        and var_16.var_52 is not redirect_pathrev):
      var_18 = 1

    
    debug.t_endstartup

    
    if var_18:
      var_16.var_11.redirect(var_16.get_url())
    else:
      debug.t_startview-func
      var_16.var_52(var_16)
      debug.t_endview-func

  def get_url(var_16, escape=0, partial=0, prefix=0, **args):
    

    var_46, var_47 = apply(var_16.get_link, (), args)
    var_48 = compat.urlencode(var_47)
    if var_48:
      var_35 = urllib.quote(var_46, var_10) + ? + var_48
    else:
      var_35 = urllib.quote(var_46, var_10)

    if partial:
      var_35 = var_35 + (var_48 and & or ?)
    if escape:
      var_35 = var_16.var_11.escape(var_35)
    if prefix:
      var_35 = %var_49://%var_49%var_49 % \
               (var_16.var_11.getenvHTTPS == on and https or http,
                var_16.var_11.getenvHTTP_HOST,
                var_35)
    return var_35

  def get_form(var_16, **args):
    

    var_46, var_47 = apply(var_16.get_link, (), args)
    var_50 = var_16.var_11.escape(urllib.quote(var_46, var_10))
    var_51 = []
    for var_19, var_21 in var_47.var_91():
      var_51.append(_item(var_19=var_16.var_11.escape(var_19),
                                 var_21=var_16.var_11.escape(var_21)))
    return var_50, var_51

  def get_link(var_16, var_52=None, var_53=None, var_54=None, var_47=None):
    

    var_12 = var_16.var_12

    if var_52 is None:
      var_52 = var_16.var_52

    if var_47 is None:
      var_47 = var_16.query_dict.copy()
    else:
      var_47 = var_47.copy()
      
    
    assert (var_53 is None) == (var_54 is None)

    
    
    if (var_52 is view_revision or var_52 is var_37
        or var_52 is redirect_pathrev):
      var_53 = var_54 = None
    elif var_53 is None:
      var_53 = var_16.var_53
      var_54 = var_16.var_54

    
    var_55 = not (var_52 is var_27 
                       or var_52 is var_38)

    
    

    var_46 = var_16.script_name

    
    if var_52 is var_27 and var_12.options.checkout_magic:
      var_46 = var_46 + / + var_2

    
    var_56 = None
    if var_52 is not var_37:
      if var_12.options.root_as_url_component:
        
        try:
          var_56 = var_47[var_22]
        except KeyError:
          var_56 = var_16.var_56
        else:
          del var_47[var_22]

        
        if var_56 is not None:
          var_46 = var_46 + / + var_56

      else:
        
        try:
          var_56 = var_47[var_22]
        except KeyError:
          var_56 = var_47[var_22] = var_16.var_56

        
        if var_56 == var_12.general.default_root:
          del var_47[var_22]   

    
    if (var_16.var_23 is not None
        and not var_47.has_keypathrev
        and var_52 is not view_revision
        and var_56 == var_16.var_56):
      var_47[var_23] = var_16.var_23

    
    if var_53:
      var_46 = var_46 + / + var_53

    
    if var_54 == vclib.DIR:
      var_46 = var_46 + /

    
    elif not var_46:
      var_46 = /

    
    if var_52 is var_39 and var_54 == vclib.DIR:
      var_52 = None

    
    
    if var_52 is var_37 and (var_12.options.root_as_url_component
                                    or not var_12.general.default_root):
      var_52 = None

    
    
    if var_52 is var_41 and var_47.getannotate is not None:
      var_52 = None

    
    
    if (var_52 is var_40 and var_47.getr1 is not None
        and var_47.getr2 is not None):
      var_52 = None

    
    
    if var_52 is var_27:
      if ((var_12.options.default_file_view == co and var_54 == vclib.FILE)
          or var_12.options.checkout_magic):
        var_52 = None

    
    if var_52 is var_44:
      if (var_12.options.default_file_view == markup \
          and var_54 == vclib.FILE):
        var_52 = None

    
    var_57 = _view_codes.get(var_52)
    if var_57 and not (var_47.has_keyview and var_47[view] is None):
      var_47[view] = var_57

    
    if var_55:
      for var_19 in _sticky_vars:
        var_21 = var_16.query_dict.get(var_19)
        if var_21 is not None and not var_47.has_key(var_19):
          var_47[var_19] = var_21

    
    for var_19, var_21 in var_47.var_91():
      if var_21 is None:
        del var_47[var_19]

    return var_46, var_47

def _path_parts(var_61):
  
  
  
  return filter(None, string.split(var_61, /))

def _normalize_path(var_61):
  
  
  var_58 = 0
  for c in var_61:
    if c != /:
      break
    var_58 = var_58 + 1

  if var_58:
    return var_61[var_58-1:]

  return var_61

def _validate_param(var_19, var_21):
  

  
  try:
    var_59 = _legal_params[var_19]
  except KeyError:
    raise debug.ViewVCException('An illegal parameter name was provided.', '400 Bad Request')

  
  
  if var_59 is None:
    return
  elif hasattr(var_59, match):
    if var_59.match(var_21):
      return
  else:
    if var_59(var_21):
      return

  
  raise debug.ViewVCException(
    An illegal var_21 was provided for the "%s" parameter. % (var_19),
    400 Bad Request)

def _validate_regex(var_21):
  
  
  
  try:
    re.compile(var_21)
    return True
  except:
    return None

def _validate_view(var_21):
  
  return _views.has_key(var_21)

def _validate_mimetype(var_21):
  
  
  return var_21 in (viewcvs_mime_type, var_4, text/plain)


_re_validate_alpha = re.compile^[a-z]+$
_re_validate_number = re.compile^[0-9]+$
_re_validate_boolint = re.compile^[01]$


_re_validate_revnum = re.compile^[-_.a-zA-Z0-9:~\[\]/]*$


_re_validate_datetime = re.compile^(\d\d\d\d-\d\d-\d\d(\var_49+\d\d:\d\d(:\d\d)?)?)?$


_legal_params = {
  var_22          : None,
  view          : _validate_view,
  search        : _validate_regex,
  p1            : None,
  p2            : None,
  
  hideattic     : _re_validate_boolint,
  limit_changes : _re_validate_number,
  sortby        : _re_validate_alpha,
  sortdir       : _re_validate_alpha,
  logsort       : _re_validate_alpha,
  diff_format   : _re_validate_alpha,
  var_23       : _re_validate_revnum,
  dir_pagestart : _re_validate_number,
  log_pagestart : _re_validate_number,
  annotate      : _re_validate_revnum,
  graph         : _re_validate_revnum,
  makeimage     : _re_validate_boolint,
  r1            : _re_validate_revnum,
  tr1           : _re_validate_revnum,
  r2            : _re_validate_revnum,
  tr2           : _re_validate_revnum,
  var_24      : _re_validate_revnum,
  content-var_32  : _validate_mimetype,

  
  file_match    : _re_validate_alpha,
  branch_match  : _re_validate_alpha,
  who_match     : _re_validate_alpha,
  comment_match : _re_validate_alpha,
  dir           : None,
  file          : None,
  branch        : None,
  who           : None,
  comment       : None,
  querysort     : _re_validate_alpha,
  date          : _re_validate_alpha,
  hours         : _re_validate_number,
  mindate       : _re_validate_datetime,
  maxdate       : _re_validate_datetime,
  format        : _re_validate_alpha,

  
  orig_path     : None,
  orig_pathtype : None,
  orig_pathrev  : None,
  orig_view     : None,

  
  parent        : _re_validate_boolint,
  var_60           : _re_validate_revnum,
  tarball       : _re_validate_boolint,
  hidecvsroot   : _re_validate_boolint,
  }

def _path_join(var_26):
  return string.join(var_26, /)

def _strip_suffix(suffix, var_26, var_60, var_54, repos, var_52):
  
  if not var_26:
    return None
  l = len(suffix)
  if var_26[-1][-l:] == suffix:
    var_26 = var_26[:]
    if len(var_26[-1]) == l:
      del var_26[-1]
    else:
      var_26[-1] = var_26[-1][:-l]
    t = _repos_pathtype(repos, var_26, var_60)
    if var_54 == t:
      return var_26, t, var_52
  return None

def _repos_pathtype(repos, var_26, var_60):
  
  try:
    return repos.itemtype(var_26, var_60)
  except vclib.ItemNotFound:
    return None

def _orig_path(var_70, rev_param=var_24, path_param=None):
  Get original var_61 of requested file at old var_24 before copies or moves

  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  var_60 = var_70.query_dict.get(rev_param, var_70.var_23)
  var_61 = var_70.query_dict.get(path_param, var_70.var_53)
  
  if var_60 is not None and hasattr(var_70.repos, _getrev):
    try:
      var_23 = var_70.repos._getrev(var_70.var_23)
      var_60 = var_70.repos._getrev(var_60)
    except vclib.InvalidRevision:
      raise debug.ViewVCException('Invalid revision', '404 Not Found')
    return _path_parts(var_70.repos.get_location(var_61, var_23, var_60)), var_60
  return _path_parts(var_61), var_60

def function_1(var_12, var_63, var_56=None):
  
  
  if var_56 is None:
    var_65 = var_12.options.var_65
    var_47 = var_12.get_authorizer_params()
  else:
    var_65, var_47 = var_12.get_authorizer_and_params_hack(var_56)

  
  if not var_65:
    return None

  
  var_66 = None
  try:
    try:
      var_66, var_61, var_67 = imp.find_module(%var_49 % (var_65), vcauth.__path__)
      var_68 = imp.load_module(viewvc, var_66, var_61, var_67)
    except ImportError:
      raise debug.ViewVCException(
        Invalid var_65 (%var_49) specified for var_22 "%s" \
        % (var_65, var_56),
        500 Internal Server Error)
  finally:
    if var_66:
      var_66.close()

  
  def function_2(var_69):
    return locate_root(var_12, var_69)

  
  return var_68.ViewVCAuthorizer(_root_lookup_func, var_63, var_47)

def function_3(var_70, mtime=None, var_76=None, weak=0):
  var_12 = var_70.var_12

  
  if not var_12.options.generate_etags:
    return 0
  
  var_74 = var_75 = None
  if var_76 is not None:
    if weak:
      var_76 = W/"%s" % var_76
    else:
      var_76 = "%s" % var_76
    var_74 = var_70.var_11.getenvHTTP_IF_NONE_MATCH
  if mtime is not None:
    try:
      var_75 = var_70.var_11.getenvHTTP_IF_MODIFIED_SINCE
      var_75 = rfc822.mktime_tz(rfc822.parsedate_tz(var_75))
    except:
      var_75 = None

  
  
  
  if var_76 is not None:
    var_77 = (var_74 == var_76)
  elif mtime is not None:
    var_77 = (var_75 >= mtime)
  else:
    var_77 = 0

  
  if var_12 and var_12.options.http_expiration_time >= 0:
    var_78 = compat.formatdate(time.time() +
                                   var_12.options.http_expiration_time)
    var_70.var_11.addheader(Expires, var_78)
    var_70.var_11.addheader(Cache-Control,
                             max-age=%d % var_12.options.http_expiration_time)

  if var_77:
    var_70.var_11.header(status=304 Not Modified)
  else:
    if var_76 is not None:
      var_70.var_11.addheader(ETag, var_76)
    if mtime is not None:
      var_70.var_11.addheader(Last-Modified, compat.formatdate(mtime))
  return var_77

def function_4(var_12, var_79, language=en):
  
  
  var_81 = vars(var_12.templates).get(var_79) or var_79 + .ezt

  
  
  var_81 = os.var_61.join(var_12.options.template_dir or templates, var_81)

  
  var_81 = string.replace(var_81, %lang%, language)

  
  var_81 = var_12.var_61(var_81)

  debug.t_startezt-parse
  var_82 = ezt.Template(var_81)
  debug.t_endezt-parse

  return var_82

def function_5(var_70, content_type=None, var_110=None,
                               content_length=None, allow_compress=True):
  

  if allow_compress and var_70.gzip_compress_level:
    var_70.var_11.addheader('Content-Encoding', 'gzip')
  elif content_length is not None:
    var_70.var_11.addheader(Content-Length, content_length)
  
  if content_type and var_110:
    var_70.var_11.header(%var_49; var_87=%var_49 % (content_type, var_110))
  elif content_type:
    var_70.var_11.header(content_type)
  else:
    var_70.var_11.header()

  if allow_compress and var_70.gzip_compress_level:
    var_66 = gzip.GzipFile(, wb, var_70.gzip_compress_level,
                       var_70.var_11.file())
  else:
    var_66 = var_70.var_11.file()
  
  return var_66
  
def function_6(var_70, var_79, var_88, content_type=None):
  var_89 = get_writeready_server_file(var_70, content_type)
  var_82 = get_view_template(var_70.var_12, var_79, var_70.language)
  var_82.generate(var_89, var_88)

def function_7(var_70):
  

  if not var_70.repos:
    return []

  var_90 = var_70.var_54 == vclib.DIR

  
  var_91 = []
  var_92 = _item(var_19=var_70.var_11.escape(var_70.repos.var_19), href=None)
  if var_70.var_26 or var_70.var_52 is not var_39:
    var_92.href = var_70.get_url(var_52=var_39,
                                     var_53=, var_54=vclib.DIR,
                                     var_47={}, escape=1)
  var_91.append(var_92)

  
  var_26 = []
  for part in var_70.var_26:
    var_26.append(part)
    var_93 = len(var_26) == len(var_70.var_26)

    var_94 = _item(var_19=var_70.var_11.escape(part), href=None)

    if not var_93 or (var_90 and var_70.var_52 is not var_39):
      var_94.href = var_70.get_url(var_52=var_39,
                                  var_53=_path_join(var_26),
                                  var_54=vclib.DIR,
                                  var_47={}, escape=1)
    elif not var_90 and var_70.var_52 is not var_45:
      var_94.href = var_70.get_url(var_52=var_45,
                                  var_53=_path_join(var_26),
                                  var_54=vclib.FILE,
                                  var_47={}, escape=1)
    var_91.append(var_94)

  return var_91

def function_8(var_70, var_95):
  var_46, var_47 = var_70.get_link(var_47={'pathrev': None})
  var_47 = compat.urlencode(var_47)
  if var_47:
    var_46 = urllib.quote(var_46, var_10) + ? + var_47 + &var_23=
  else:
    var_46 = urllib.quote(var_46, var_10) + ?var_23=
  var_46 = var_70.var_11.escape(var_46)

  var_96 = []
  for tag in var_95:
    var_96.append(_item(var_19=tag.var_19, href=var_46+tag.var_19))
  var_96.sort<function <lambda> at 0x7f07360e8ea0>
  return var_96

def function_9(var_97):
  return mimetypes.guess_type(var_97)[0]

def function_10(var_98):
  return var_98 and var_98 in ('image/gif', 'image/jpeg', 'image/png')

def function_11(var_98):
  return not var_98 or var_98[:5] == text/

def function_12(var_30, var_26):
  return var_30 == var_34 and var_26 and var_26[0] == CVSROOT

def function_13(var_98):
  return not var_98 or var_98 == text/plain

def function_14(var_98, var_12):
  Determine whether file should be viewed through markup page or sent raw
  
  
  
  
  
  
  
  if (markup in var_12.options.allowed_views and 
      (is_viewable_image(var_98) or is_text(var_98))):
    return var_44
  return var_27

def function_15(var_98, var_12):
  
  if var_98:
    for pattern in var_12.options.binary_mime_types:
      if fnmatch.fnmatch(var_98, pattern):
        return True
  return False
  
def function_16(var_70, var_53, var_60=None, var_98=None, var_23=-1):
  
  
  var_60 = var_60 and str(var_60) or None
  var_98 = var_98 or guess_mime(var_53)
  if var_23 == -1: 
    var_23 = var_70.var_23

  var_102 = None
  var_103 = None
  var_104 = None
  var_105 = None
  var_106 = None

  if markup in var_70.var_12.options.allowed_views:
    var_102 = var_70.get_url(var_52=var_44,
                                var_53=var_53,
                                var_54=vclib.FILE,
                                var_47={var_24: var_60,
                                        var_23: var_23},
                                escape=1)
  if co in var_70.var_12.options.allowed_views:
    var_103 = var_70.get_url(var_52=var_27,
                                    var_53=var_53,
                                    var_54=vclib.FILE,
                                    var_47={var_24: var_60,
                                            var_23: var_23},
                                    escape=1)
    if not is_plain_text(var_98):
      var_104 = var_70.get_url(var_52=var_27,
                                           var_53=var_53,
                                           var_54=vclib.FILE,
                                           var_47={content-var_32: text/plain,
                                                   var_24: var_60,
                                                   var_23: var_23},
                                           escape=1)
  if annotate in var_70.var_12.options.allowed_views:
    var_105 = var_70.get_url(var_52=var_41,
                                    var_53=var_53,
                                    var_54=vclib.FILE,
                                    var_47={annotate: var_60,
                                            var_23: var_23},
                                    escape=1)
  if var_70.var_30 == var_33:
    var_106 = var_70.get_url(var_52=view_revision,
                                    var_47={var_24: var_60},
                                    escape=1)

  var_107 = is_binary_file_mime_type(var_98, var_70.var_12)
  if var_107:
    var_104 = var_105 = var_102 = None
    var_108 = False
  else:
    var_108 = default_view(var_98, var_70.var_12) == var_44

  return _item(var_102=var_102,
               var_103=var_103,
               var_104=var_104,
               var_105=var_105,
               var_106=var_106,
               var_108=ezt.boolean(var_108))



_re_rewrite_url = re.compile(((http|https|ftp|file|var_33|var_33\+ssh)
                             (://[-a-zA-Z0-9%.~:_/]+)((\?|\&)
                             ([-a-zA-Z0-9%.~:_]+)=([-a-zA-Z0-9%.~:_])+)*
                             '(

_re_rewrite_email = re.compile([-a-zA-Z0-9_.\+]+)@(([-a-zA-Z0-9]+pygments.lexers.\.)+[A-Za-z]{2,4})


_re_rewrite_svnrevref = re.compile(r'\b(r|var_60 

class ViewVCHtmlFormatterTokens:
  def __init__(var_16, tokens):
    var_16.tokens = tokens

  def get_result(var_16, maxlen=0):
    
    out = 
    out_len = 0
    for token in var_16.tokens:
      chunk, chunk_len = token.converter(token.match, token.userdata, maxlen)
      out = out + chunk
      out_len = out_len + chunk_len
      if maxlen:
        maxlen = maxlen - chunk_len
        if maxlen <= 0:
          return out, out_len, 1
    return out, out_len, 0

    
class ViewVCHtmlFormatter:
  
  
  def __init__(var_16):
    var_16._formatters = []

  def format_url(var_16, mobj, userdata, maxlen=0):
    
    var_49 = mobj.group0
    trunc_s = maxlen and var_49[:maxlen] or var_49
    return <a href="%s">%var_49</a> % (sapi.escape(var_49),
                                    sapi.escape(trunc_s)), \
           len(trunc_s)

  def format_email(var_16, mobj, userdata, maxlen=0):
    
    var_49 = mobj.group0
    trunc_s = maxlen and var_49[:maxlen] or var_49
    return <a href="mailto:%s">%var_49</a> % (urllib.quote(var_49),
                                           var_16._entity_encode(trunc_s)), \
           len(trunc_s)

  def format_email_obfuscated(var_16, mobj, userdata, maxlen=0):
        
    var_49 = mobj.group0
    trunc_s = maxlen and var_49[:maxlen] or var_49
    return var_16._entity_encode(trunc_s), len(trunc_s)

  def format_email_truncated(var_16, mobj, userdata, maxlen=0):
    
    var_49 = mobj.group1
    s_len = len(var_49)
    if (maxlen == 0) or (s_len < (maxlen - 1)):
      return var_16._entity_encode(var_49) + '&
    elif s_len < maxlen:
      return var_16._entity_encode(var_49) + '&
    else:
      trunc_s = mobj.group1[:maxlen]
      return var_16._entity_encode(trunc_s), len(trunc_s)

  def format_svnrevref(var_16, mobj, userdata, maxlen=0):
    
    var_49 = mobj.group0
    revref = mobj.group2
    trunc_s = maxlen and var_49[:maxlen] or var_49
    revref_url = userdata(revref)
    return <a href="%s">%var_49</a> % (sapi.escape(revref_url),
                                    sapi.escape(trunc_s)), \
           len(trunc_s)

  def format_custom_url(var_16, mobj, userdata, maxlen=0):
    
    format = userdata
    text = mobj.group0
    var_46 = format
    for var_58 in range9:
      try:
        repl = mobj.group(var_58)
      except:
        repl = 
      var_46 = var_46.replace(\%d % (var_58), repl)
    trunc_s = maxlen and text[:maxlen] or text
    return <a href="%s">%var_49</a> % (sapi.escape(var_46),
                                    sapi.escape(trunc_s)), \
           len(trunc_s)

  def format_text(var_16, var_49, unused, maxlen=0):
       
    trunc_s = maxlen and var_49[:maxlen] or var_49
    return sapi.escape(trunc_s), len(trunc_s)
  
  def add_formatter(var_16, regexp, conv, userdata=None):
    
    if var_32(regexp) == var_32:
      regexp = re.compile(regexp)
    var_16._formatters.append([regexp, conv, userdata])

  def get_result(var_16, var_49, maxlen=0):
    
    return var_16.tokenize_text(var_49).get_result(maxlen)

  def tokenize_text(var_16, var_49):
    
    tokens = []
    
    
    
    
    for line in string.split(string.replace(var_49, 
, 
), 
):
      line = line + 

      while line:
        best_match = best_conv = best_userdata = None
        for test in var_16._formatters:
          match = test[0].search(line)
          
          
          
          
          
          
          
          
          if match \
             and ((best_match is None) \
                  or (match.start() < best_match.start())
                  or ((match.start() == best_match.start()) \
                      and (match.end() > best_match.end()))):
            best_match = match
            best_conv = test[1]
            best_userdata = test[2]
        
        if best_match:
          
          start = best_match.start()
          end = best_match.end()
          if start > 0:
            tokens.append(_item(match=line[:start],
                                converter=var_16.format_text,
                                userdata=None))
          tokens.append(_item(match=best_match,
                              converter=best_conv,
                              userdata=best_userdata))
          line = line[end:]
        else:
          
          tokens.append(_item(match=line,
                              converter=var_16.format_text,
                              userdata=None))
          line = 
    return ViewVCHtmlFormatterTokens(tokens)

  def _entity_encode(var_16, var_49):
    return string.join(map(lambda x: '&


class LogFormatter:
  def __init__(var_16, var_70, log):
    var_16.var_70 = var_70
    var_16.log = log or 
    var_16.tokens = None
    var_16.cache = {}  

  def get(var_16, maxlen=0, htmlize=1):
    var_12 = var_16.var_70.var_12
    
    
    if var_16.cache.has_key((maxlen, htmlize)):
      return var_16.cache[(maxlen, htmlize)]
    
    
    if htmlize:
      
      if not var_16.tokens:
        
        lf = ViewVCHtmlFormatter()

        
        lf.add_formatter(_re_rewrite_url, lf.format_url)

        
        if var_16.var_70.var_30 == var_33:
          def revision_to_url(var_60):
            return var_16.var_70.get_url(var_52=view_revision,
                                        var_47={var_24: var_60},
                                        escape=0)
          lf.add_formatter(_re_rewrite_svnrevref, lf.format_svnrevref,
                           revision_to_url)

        
        if var_12.options.mangle_email_addresses == 2:
          lf.add_formatter(_re_rewrite_email, lf.format_email_truncated)
        elif var_12.options.mangle_email_addresses == 1:
          lf.add_formatter(_re_rewrite_email, lf.format_email_obfuscated)
        else:
          lf.add_formatter(_re_rewrite_email, lf.format_email)

        
        for rule in var_12.options.custom_log_formatting:
          rule = rule.replace('\\:', '\x01')          
          regexp, format = map(<function <lambda> at 0x7f07360e8f40>, rule.split(':', 1))
          regexp = regexp.replace('\x01', ':')
          format = format.replace('\x01', ':')
          lf.add_formatter(re.compile(regexp), lf.format_custom_url, format)

        
        var_16.tokens = lf.tokenize_text(var_16.log)

      
      log, log_len, truncated = var_16.tokens.get_result(maxlen)
      result_log = log + (truncated and &hellip; or )

    
    else:
      
      log = var_16.log
      if var_12.options.mangle_email_addresses == 2:
        log = re.sub(_re_rewrite_email, \1@..., log)
      result_log = maxlen and log[:maxlen] or log

    
    var_16.cache[(maxlen, htmlize)] = result_log
    return result_log


_time_desc = {1: 'second', 60: 'minute', 3600: 'hour', 86400: 'day', 604800: 'week', 2628000: 'month', 31536000: 'year'}

def get_time_text(var_70, interval, num):
  Get some time text, possibly internationalized.
  
  
  if num == 0:
    return 
  text = _time_desc[interval]
  if num == 1:
    attr = text + _singular
    fmt = %d  + text
  else:
    attr = text + _plural
    fmt = %d  + text + var_49
  try:
    fmt = getattr(var_70.kv.i18n.time, attr)
  except AttributeError:
    pass
  return fmt % num

def little_time(var_70):
  try:
    return var_70.kv.i18n.time.little_time
  except AttributeError:
    return very little time

def html_time(var_70, secs, extended=0):
  secs = long(time.time()) - secs
  if secs < 2:
    return little_time(var_70)
  breaks = _time_desc.keys()
  breaks.sort()
  var_58 = 0
  while var_58 < len(breaks):
    if secs < 2 * breaks[var_58]:
      break
    var_58 = var_58 + 1
  var_21 = breaks[var_58 - 1]
  var_49 = get_time_text(var_70, var_21, secs / var_21)

  if extended and var_58 > 1:
    secs = secs % var_21
    var_21 = breaks[var_58 - 2]
    ext = get_time_text(var_70, var_21, secs / var_21)
    if ext:
      
      var_49 = var_49 + ,  + ext
  return var_49

def common_template_data(var_70, var_24=None, var_98=None):
  
  
  var_12 = var_70.var_12

  
  var_88 = ezt.TemplateData({
    var_105 : None,
    var_12 : var_12,
    docroot : var_12.options.docroot is None \
                and var_70.script_name + / + var_3 \
                or var_12.options.docroot,
    var_103 : None,
    var_104 : None,
    graph_href: None,
    kv  : var_70.kv,
    lockinfo : None,
    log_href : None,
    nav_path : nav_path(var_70),
    var_54 : None,
    var_108 : ezt.boolean0,
    queryform_href : None,
    var_60      : None,
    var_106 : None,
    var_56 : var_70.var_56 \
                 and var_70.var_11.escape(var_70.var_56) or None,
    var_31 : var_70.var_31,
    roots_href : None,
    var_30 : var_70.var_30,
    rss_href : None,
    tarball_href : None,
    up_href  : None,
    var_63 : var_70.var_63,
    view     : _view_codes[var_70.var_52],
    var_102 : None,
    vsn : var_0,
    var_53 : var_70.var_11.escape(var_70.var_53),
  })

  var_60 = var_24
  if not var_60:
    var_60 = var_70.query_dict.getannotate
  if not var_60:
    var_60 = var_70.query_dict.getrevision
  if not var_60 and var_70.var_30 == var_33:
    var_60 = var_70.query_dict.getpathrev
  try:
    var_88[var_60] = hasattr(var_70.repos, _getrev) \
                  and var_70.repos._getrev(var_60) or var_60
  except vclib.InvalidRevision:
    raise debug.ViewVCException('Invalid revision', '404 Not Found')

  if var_70.var_54 == vclib.DIR:
    var_88[var_54] = dir
  elif var_70.var_54 == vclib.FILE:
    var_88[var_54] = file

  if var_70.var_26:
    dir = _path_join(var_70.var_26[:-1])
    var_88[up_href] = var_70.get_url(var_52=var_39,
                                      var_53=dir, var_54=vclib.DIR,
                                      var_47={}, escape=1)

  if roots in var_12.options.allowed_views:
    var_88[roots_href] = var_70.get_url(var_52=var_37,
                                         escape=1, var_47={})

  if var_70.var_54 == vclib.FILE:
    fvi = get_file_view_info(var_70, var_70.var_53, var_88[var_60], var_98)
    var_88[var_102] = fvi.var_102
    var_88[var_103] = fvi.var_103
    var_88[var_104] = fvi.var_104
    var_88[var_105] = fvi.var_105
    var_88[var_106] = fvi.var_106
    var_88[var_108] = fvi.var_108
    var_88[log_href] = var_70.get_url(var_52=var_45, var_47={}, escape=1)
    if var_70.var_30 == var_34 and var_12.options.use_cvsgraph:
      var_88[graph_href] = var_70.get_url(var_52=var_42,
                                           var_47={}, escape=1)
    file_data = var_70.repos.listdir(var_70.var_26[:-1],
                                      var_70.var_23, {})
    def _only_this_file(var_94):
      return var_94.var_19 == var_70.var_26[-1]
    entries = filter(_only_this_file, file_data)
    if len(entries) == 1:
      var_70.repos.dirlogs(var_70.var_26[:-1], var_70.var_23,
                            entries, {})
      var_88[lockinfo] = entries[0].lockinfo
  elif var_70.var_54 == vclib.DIR:
    var_88[var_102] = var_70.get_url(var_52=var_39,
                                       var_47={}, escape=1)
    if tar in var_12.options.allowed_views:
      var_88[tarball_href] = var_70.get_url(var_52=var_38, 
                                             var_47={},
                                             escape=1)
    if var_70.var_30 == var_33:
      var_88[var_106] = var_70.get_url(var_52=view_revision,
                                              var_47={var_24: var_88[var_60]},
                                              escape=1)

      var_88[log_href] = var_70.get_url(var_52=var_45,
                                         var_47={}, escape=1)

  if is_querydb_nonempty_for_root(var_70):
    if var_70.var_54 == vclib.DIR:
      var_47 = {}
      if var_70.var_30 == var_34 and var_70.var_23:
        var_47[branch] = var_70.var_23
      var_88[queryform_href] = var_70.get_url(var_52=view_queryform,
                                               var_47=var_47,
                                               escape=1)
      var_88[rss_href] = var_70.get_url(var_52=view_query,
                                         var_47={'date': 'month', 'format': 'rss'},
                                         escape=1)
    elif var_70.var_54 == vclib.FILE:
      parts = _path_parts(var_70.var_53)
      var_53 = _path_join(parts[:-1])
      var_88[rss_href] = var_70.get_url(var_52=view_query,
                                         var_53=var_53,
                                         var_54=var_70.var_54,
                                         var_47={date: month,
                                                 format: rss,
                                                 file: parts[-1],
                                                 file_match: exact},
                                         escape=1)
  return var_88

def retry_read(src, reqlen=var_6):
  while 1:
    chunk = src.read(var_6)
    if not chunk:
      
      
      if hasattr(src, eof) and src.eof() is None:
        time.sleep1
        continue
    return chunk
  
def copy_stream(src, dst, htmlize=0):
  while 1:
    chunk = retry_read(src)
    if not chunk:
      break
    if htmlize:
      chunk = sapi.escape(chunk)
    dst.write(chunk)

class MarkupPipeWrapper:
  

  def __init__(var_16, var_66, pretext=None, posttext=None, htmlize=0):
    var_16.var_66 = var_66
    var_16.pretext = pretext
    var_16.posttext = posttext
    var_16.htmlize = htmlize

  def __call__(var_16, ctx):
    if var_16.pretext:
      ctx.var_66.write(var_16.pretext)
    copy_stream(var_16.var_66, ctx.var_66, var_16.htmlize)
    var_16.var_66.close()
    if var_16.posttext:
      ctx.var_66.write(var_16.posttext)

_re_rewrite_escaped_url = re.compile(((http|https|ftp|file|var_33|var_33\+ssh)
                                     (://[-a-zA-Z0-9%.~:_/]+)
                                     ((\?|\&amp;amp;|\&amp;|\&)
                                     ([-a-zA-Z0-9%.~:_]+)=([-a-zA-Z0-9%.~:_])+)*
                                     '(

def markup_escaped_urls(var_49):
  
  
  def _url_repl(match_obj):
    var_46 = match_obj.group0
    unescaped_url = string.replace(var_46, &amp;amp;, &amp;)
    return <a href="%s">%var_49</a> % (unescaped_url, var_46)
  return re.sub(_re_rewrite_escaped_url, _url_repl, var_49)


def detect_encoding(text_block):
  
  
  
  for var_109, var_110 in [('ï»¿', 'utf-8'), ('ÿþ', 'utf-16'), ('þÿ', 'utf-16be'), ('ÿþ\x00\x00', 'utf-32'), ('\x00\x00þÿ', 'utf-32be')]:
    if text_block[:len(var_109)] == var_109:
      return var_110

  
  try:

    
    
    
    resp = chardet.detect(text_block)
    if resp.getconfidence == 1.0:
      var_110 = resp.getencoding
      if var_110 is ascii:
        var_110 = utf-8
      return var_110
  except:
    pass

  
  return None
  
def transcode_text(text, var_110=None):
  

  if not var_110 or var_110 == utf-8:
    return text
  try:
    return unicode(text, var_110, replace).encode('utf-8', 'replace')
  except:
    pass
  return text

def markup_stream(var_70, var_12, blame_data, file_lines, var_97,
                  var_98, var_110, colorize):
  
  
  
  if not file_lines:
    return []

  
  
  
  
  pygments_lexer = None
  if colorize:
    from pygments import highlight
    from pygments.formatters import HtmlFormatter
    from pygments.lexers import ClassNotFound, \
                                get_lexer_by_name, \
                                get_lexer_for_mimetype, \
                                get_lexer_for_filename, \
                                guess_lexer
    if not var_110:
      var_110 = guess
      if var_12.options.detect_encoding:
        try:
          var_110 = chardet
        except (SyntaxError, ImportError):
          pass

    
    if var_98:
      try:
        pygments_lexer = get_lexer_for_mimetype(var_98,
                                                var_110=var_110,
                                                tabsize=var_12.options.tabsize,
                                                stripnl=False)
      except ClassNotFound:
        pygments_lexer = None

    
    if not pygments_lexer:
      try:
        pygments_lexer = get_lexer_for_filename(var_97,
                                                var_110=var_110,
                                                tabsize=var_12.options.tabsize,
                                                stripnl=False)
      except ClassNotFound:
        pygments_lexer = None

    
    
    if not pygments_lexer and is_text(var_98) and file_lines:
      try:
        pygments_lexer = guess_lexer(file_lines[0],
                                     var_110=var_110,
                                     tabsize=var_12.options.tabsize,
                                     stripnl=False)
      except ClassNotFound:
        pygments_lexer = None
        
  
  
  if not pygments_lexer:

    
    
    
    if not var_110 and var_12.options.detect_encoding:
      block_size = 0
      text_block = 
      for var_58 in range(len(file_lines)):
        text_block = text_block + file_lines[var_58]
        if len(text_block) >= 1024:
          break
      var_110 = detect_encoding(text_block)

    
    
    
    lines = []
    file_lines = transcode_text(string.join(file_lines, ), var_110)
    if file_lines[-1] == 
:
      file_lines = file_lines[:-1]
    file_lines = string.split(file_lines, 
)
    for var_58 in range(len(file_lines)):
      line = file_lines[var_58]
      if var_12.options.tabsize > 0:
        line = string.expandtabs(line, var_12.options.tabsize)
      line = markup_escaped_urls(sapi.escape(line))
      if blame_data:
        blame_item = blame_data[var_58]
        blame_item.text = line
      else:
        blame_item = vclib.Annotation(line, var_58 + 1, None, None, None, None)
        blame_item.diff_href = None
      lines.append(blame_item)
    return lines

  
  class PygmentsSink:
    def __init__(var_16, blame_data):
      if blame_data:
        var_16.has_blame_data = 1
        var_16.blame_data = blame_data
      else:
        var_16.has_blame_data = 0
        var_16.blame_data = []
      var_16.line_no = 0
    def write(var_16, buf):
      
      buf = markup_escaped_urls(string.rstrip(buf, 
))
      if var_16.has_blame_data:
        var_16.blame_data[var_16.line_no].text = buf
      else:
        var_94 = vclib.Annotation(buf, var_16.line_no + 1,
                                None, None, None, None)
        var_94.diff_href = None
        var_16.blame_data.append(var_94)
      var_16.line_no = var_16.line_no + 1

  ps = PygmentsSink(blame_data)
  highlight(string.join(file_lines, ), pygments_lexer,
            HtmlFormatter(nowrap=True,
                          classprefix=pygments-,
                          var_110=utf-8), ps)
  return ps.blame_data

def make_time_string(date, var_12):
  
  if date is None:
    return None
  if var_12.options.use_localtime:
    tm = time.localtime(date)
  else:
    tm = time.gmtime(date)
  if var_12.options.iso8601_timestamps:
    if var_12.options.use_localtime:
      if tm[8] and time.daylight:
        tz = -time.altzone
      else:
        tz = -time.timezone
      tz = float(tz) / 3600.0
      tz = string.replace(str.format({0:+06.2f}, tz), ., :)
    else:
      tz = Z
    return time.strftime(%Y-%m-%dT%H:%M:%S, tm) + tz
  else:
    return time.asctime(tm) +   + \
           (var_12.options.use_localtime and time.tzname[tm[8]] or UTC)

def make_rss_time_string(date, var_12):
  
  if date is None:
    return None
  return time.strftime(%a, %d %b %Y %H:%M:%S, time.gmtime(date)) +  UTC

def make_comma_sep_list_string(var_91):
  return string.join(map(<function <lambda> at 0x7f07360e8040>, var_91), , )

def get_itemprops(var_70, var_26, var_60):
  itemprops = var_70.repos.itemprops(var_26, var_60)
  propnames = itemprops.keys()
  propnames.sort()
  props = []
  for var_19 in propnames:
    lf = LogFormatter(var_70, itemprops[var_19])
    var_21 = lf.get(maxlen=0, htmlize=1)
    undisplayable = ezt.boolean0
    
    try:
      unicode(var_19, utf8)
    except:
      continue
    
    try:
      unicode(var_21, utf8)
    except:
      var_21 = None
      undisplayable = ezt.boolean1
    props.append(_item(var_19=var_19, var_21=var_21, undisplayable=undisplayable))
  return props

def parse_mime_type(var_98):
  mime_parts = map(<function <lambda> at 0x7f07360e80e0>, string.split(var_98, ;))
  type_subtype = mime_parts[0].lower()
  parameters = {}
  for part in mime_parts[1:]:
    var_19, var_21 = string.split(part, =, 1)
    parameters[var_19] = var_21
  return type_subtype, parameters
  
def calculate_mime_type(var_70, var_26, var_60):
  
  if not var_26:
    return None, None
  var_98 = var_110 = None
  if var_70.var_30 == var_33 \
     and (not var_70.var_12.options.svn_ignore_mimetype):
    try:
      itemprops = var_70.repos.itemprops(var_26, var_60)
      var_98 = itemprops.getsvn:mime-var_32
      if var_98:
        var_98, parameters = parse_mime_type(var_98)
        return var_98, parameters.getcharset
    except:
      pass
  return guess_mime(var_26[-1]), None

def assert_viewable_filesize(var_12, filesize):
  if var_12.options.max_filesize_kbytes \
     and filesize != -1 \
     and filesize > (1024 * var_12.options.max_filesize_kbytes):
    raise debug.ViewVCException(Display of files larger than %d KB 
                                disallowed by configuration
                                % (var_12.options.max_filesize_kbytes),
                                403 Forbidden)
  
def markup_or_annotate(var_70, is_annotate):
  var_12 = var_70.var_12
  var_61, var_60 = _orig_path(var_70, is_annotate and annotate or var_24)
  lines = var_66 = image_src_href = None
  annotation = none
  var_24 = None
  var_98, var_110 = calculate_mime_type(var_70, var_61, var_60)

  
  if is_binary_file_mime_type(var_98, var_12):
    raise debug.ViewVCException('Display of binary file content disabled by configuration', '403 Forbidden')
    
  
  if is_viewable_image(var_98) \
     and co in var_12.options.allowed_views:
    var_66, var_24 = var_70.repos.openfile(var_61, var_60, {})
    var_66.close()
    if check_freshness(var_70, None, var_24, weak=1):
      return
    if is_annotate:
      annotation = binary
    image_src_href = var_70.get_url(var_52=var_27,
                                     var_47={var_24: var_60}, escape=1)

  
  else:
    filesize = var_70.repos.filesize(var_61, var_60)

    
    
    assert_viewable_filesize(var_12, filesize)

    
    
    
    blame_data = None
    if is_annotate:
      try:
        blame_source, var_24 = var_70.repos.annotate(var_61, var_60, False)
        if check_freshness(var_70, None, var_24, weak=1):
          return
        
        
        blame_data = []
        for var_94 in blame_source:
          var_94.diff_href = None
          if var_94.prev_rev:
            var_94.diff_href = var_70.get_url(var_52=var_40,
                                             var_47={r1: var_94.prev_rev,
                                                     r2: var_94.var_60},
                                             escape=1, partial=1)
          blame_data.append(var_94)
        annotation = annotated
      except vclib.NonTextualFileContents:
        annotation = binary
      except:
        annotation = var_9

    
    var_66, var_24 = var_70.repos.openfile(var_61, var_60, {'cvs_oldkeywords': 1})
    if check_freshness(var_70, None, var_24, weak=1):
      var_66.close()
      return

    
    
    
    if var_12.options.max_filesize_kbytes and filesize == -1:
      file_lines = []
      filesize = 0
      while 1:
        line = var_66.readline()
        if not line:
          break
        filesize = filesize + len(line)
        assert_viewable_filesize(var_12, filesize)
        file_lines.append(line)
    else:
      file_lines = var_66.readlines()
    var_66.close()

    
    
    
    if blame_data and (len(file_lines) != len(blame_data)):
      annotation = var_9
      blame_data = None

    
    
    
    colorize = var_12.options.enable_syntax_coloration
    try:
      lines = markup_stream(var_70, var_12, blame_data, file_lines,
                            var_61[-1], var_98, var_110, colorize)
    except:
      if colorize:
        lines = markup_stream(var_70, var_12, blame_data, file_lines,
                              var_61[-1], var_98, var_110, False)
      else:
        raise debug.ViewVCException('Error displaying file contents', '500 Internal Server Error')

  var_88 = common_template_data(var_70, var_24, var_98)
  var_88.merge(ezt.TemplateData({
    var_98 : var_98,
    log : None,
    date : None,
    ago : None,
    author : None,
    branches : None,
    var_95 : None,
    branch_points : None,
    changed : None,
    size : None,
    state : None,
    vendor_branch : None,
    prev : None,
    orig_path : None,
    orig_href : None,
    image_src_href : image_src_href,
    lines : lines,
    properties : get_itemprops(var_70, var_61, var_60),
    annotation : annotation,
    }))

  if var_12.options.show_log_in_markup:
    options = {'svn_latest_log': 1, 'svn_cross_copies': 1}
    revs = var_70.repos.itemlog(var_61, var_24, vclib.SORTBY_REV,
                                 0, 1, options)
    entry = revs[-1]
    lf = LogFormatter(var_70, entry.log)

    var_88[date] = make_time_string(entry.date, var_12)
    var_88[author] = entry.author
    var_88[changed] = entry.changed
    var_88[log] = lf.get(maxlen=0, htmlize=1)
    var_88[size] = entry.size

    if entry.date is not None:
      var_88[ago] = html_time(var_70, entry.date, 1)

    if var_70.var_30 == var_34:
      branch = entry.branch_number
      prev = entry.prev or entry.parent
      var_88[state] = entry.dead and dead
      var_88[prev] = prev and prev.string
      var_88[vendor_branch] = ezt.boolean(branch and branch[2] % 2 == 1)

      
      var_88[branches] = make_comma_sep_list_string(entry.branches)
      var_88[var_95] = make_comma_sep_list_string(entry.var_95)
      var_88[branch_points]= make_comma_sep_list_string(entry.branch_points)

  if var_61 != var_70.var_26:
    orig_path = _path_join(var_61)
    var_88[orig_path] = orig_path
    var_88[orig_href] = var_70.get_url(var_52=var_45,
                                        var_53=orig_path,
                                        var_54=vclib.FILE,
                                        var_47={var_23: var_24},
                                        escape=1)
    
  generate_page(var_70, file, var_88)
  
def var_44(var_70):
  if markup not in var_70.var_12.options.allowed_views:
    raise debug.ViewVCException('Markup view is disabled', '403 Forbidden')
  if var_70.var_54 != vclib.FILE:
    raise debug.ViewVCException('Unsupported feature: markup view on directory', '400 Bad Request')
  markup_or_annotate(var_70, 0)

def var_41(var_70):
  if annotate not in var_70.var_12.options.allowed_views:
    raise debug.ViewVCException('Annotation view is disabled', '403 Forbidden')
  if var_70.var_54 != vclib.FILE:
    raise debug.ViewVCException('Unsupported feature: annotate view on directory', '400 Bad Request')
  markup_or_annotate(var_70, 1)

def revcmp(rev1, rev2):
  rev1 = map(int, string.split(rev1, .))
  rev2 = map(int, string.split(rev2, .))
  return cmp(rev1, rev2)

def sort_file_data(file_data, var_30, sortdir, sortby, group_dirs):
  
  var_49 = sortdir == down and -1 or 1

  
  
  if var_30 == var_34 and sortby == var_60:
    sortby = date

  def file_sort_sortby(file1, file2, sortby):
    
    if sortby == var_60:
      return var_49 * revcmp(file1.var_60, file2.var_60)
    elif sortby == date:
      return var_49 * cmp(file2.date, file1.date)        
    elif sortby == log:
      return var_49 * cmp(file1.log, file2.log)
    elif sortby == author:
      return var_49 * cmp(file1.author, file2.author)
    return var_49 * cmp(file1.var_19, file2.var_19)

  def file_sort_cmp(file1, file2, sortby=sortby, group_dirs=group_dirs, var_49=var_49):
    
    
    
    if group_dirs:
      if file1.kind == vclib.DIR:
        if file2.kind == vclib.DIR:
          
          return file_sort_sortby(file1, file2, sortby)
        else:
          
          return -1
      elif file2.kind == vclib.DIR:
        
        return 1

    
    
    if file1.var_60 is not None and file2.var_60 is not None:
      return file_sort_sortby(file1, file2, sortby)
    elif file1.var_60 is not None:
      return -1
    elif file2.var_60 is not None:
      return 1

    
    return var_49 * cmp(file1.var_19, file2.var_19)

  file_data.sort(file_sort_cmp)

def icmp(x, y):
  
  return cmp(string.lower(x), string.lower(y))

def var_37(var_70):
  if roots not in var_70.var_12.options.allowed_views:
    raise debug.ViewVCException('Root listing view is disabled', '403 Forbidden')
  
  
  roots = []
  expand_root_parents(var_70.var_12)
  allroots = list_roots(var_70)
  if len(allroots):
    rootnames = allroots.keys()
    rootnames.sort(icmp)
    for var_56 in rootnames:
      root_path, root_type, lastmod = allroots[var_56]
      href = var_70.get_url(var_52=var_39,
                             var_53=, var_54=vclib.DIR,
                             var_47={var_22: var_56}, escape=1)
      if root_type == vclib.SVN:
        log_href = var_70.get_url(var_52=var_45,
                                   var_53=, var_54=vclib.DIR,
                                   var_47={var_22: var_56}, escape=1)
      else:
        log_href = None
      roots.append(_item(var_19=var_70.var_11.escape(var_56),
                         var_32=root_type,
                         var_61=root_path,
                         author=lastmod and lastmod.author or None,
                         ago=lastmod and lastmod.ago or None,
                         date=lastmod and lastmod.date or None,
                         log=lastmod and lastmod.log or None,
                         short_log=lastmod and lastmod.short_log or None,
                         var_60=lastmod and lastmod.var_60 or None,
                         href=href,
                         log_href=log_href))

  var_88 = common_template_data(var_70)
  var_88.merge(ezt.TemplateData({
    roots : roots,
    }))
  generate_page(var_70, roots, var_88)

def var_39(var_70):
  var_12 = var_70.var_12

  
  
  
  if var_70.var_30 == var_33:
    try:
      var_60 = var_70.repos._getrev(var_70.var_23)
    except vclib.InvalidRevision:
      raise debug.ViewVCException('Invalid revision', '404 Not Found')
    tree_rev = var_70.repos.created_rev(var_70.var_53, var_60)
    if check_freshness(var_70, None, str(tree_rev), weak=1):
      return

  
  options = {}
  if var_70.var_30 == var_34:
    hideattic = int(var_70.query_dict.get(hideattic, 
                                           var_12.options.hide_attic))
    options[cvs_subdirs] = (var_12.options.show_subdir_lastmod and
                              var_12.options.show_logs)
  file_data = var_70.repos.listdir(var_70.var_26, var_70.var_23,
                                    options)

  
  sortby = var_70.query_dict.get(sortby, var_12.options.sort_by) or file
  sortdir = var_70.query_dict.get('sortdir', 'up')

  
  
  
  
  
  debug.t_startdirlogs
  if var_12.options.dir_pagesize and sortby == file:
    dirlogs_first = int(var_70.query_dict.get('dir_pagestart', 0))
    if dirlogs_first > len(file_data):
      dirlogs_first = 0
    dirlogs_last = dirlogs_first + var_12.options.dir_pagesize
    for file in file_data:
      file.var_60 = None
      file.date = None
      file.log = None
      file.author = None
      file.size = None
      file.lockinfo = None
      file.dead = None
    sort_file_data(file_data, var_70.var_30, sortdir, sortby,
                   var_12.options.sort_group_dirs)
    
    var_70.repos.dirlogs(var_70.var_26, var_70.var_23,
                          file_data[dirlogs_first:dirlogs_last], options)
  else:
    var_70.repos.dirlogs(var_70.var_26, var_70.var_23,
                          file_data, options)
    sort_file_data(file_data, var_70.var_30, sortdir, sortby,
                   var_12.options.sort_group_dirs)
  debug.t_enddirlogs

  
  searchstr = None
  search_re = var_70.query_dict.get('search', '')
  if var_12.options.use_re_search and search_re:
    searchstr = re.compile(search_re)

  
  rows = []
  num_displayed = 0
  num_dead = 0
  
  
  var_53 = var_70.var_53
  where_prefix = var_53 and var_53 + /

  for file in file_data:
    row = _item(author=None, log=None, short_log=None, state=None, size=None,
                log_file=None, log_rev=None, graph_href=None, var_98=None,
                date=None, ago=None, var_102=None, log_href=None,
                var_106=None, var_105=None, var_103=None,
                var_104=None, var_108=ezt.boolean0)
    if var_70.var_30 == var_34 and file.absent:
      continue
    if var_12.options.hide_errorful_entries and file.errors:
      continue
    row.var_60 = file.var_60
    row.author = file.author
    row.state = (var_70.var_30 == var_34 and file.dead) and dead or 
    if file.date is not None:
      row.date = make_time_string(file.date, var_12)
      row.ago = html_time(var_70, file.date)
    if var_12.options.show_logs:
      debug.t_startdirview_logformat
      lf = LogFormatter(var_70, file.log)
      row.log = lf.get(maxlen=0, htmlize=1)
      row.short_log = lf.get(maxlen=var_12.options.short_log_len, htmlize=1)
      debug.t_enddirview_logformat
    row.lockinfo = file.lockinfo
    row.anchor = var_70.var_11.escape(file.var_19)
    row.var_19 = var_70.var_11.escape(file.var_19)
    row.var_54 = (file.kind == vclib.FILE and file) or \
                   (file.kind == vclib.DIR and dir)
    row.errors = file.errors

    if file.kind == vclib.DIR:
      if var_12.options.hide_cvsroot \
         and is_cvsroot_path(var_70.var_30,
                             var_70.var_26 + [file.var_19]):
        continue
    
      row.var_102 = var_70.get_url(var_52=var_39,
                                      var_53=where_prefix+file.var_19,
                                      var_54=vclib.DIR,
                                      var_47={},
                                      escape=1)

      if var_70.var_30 == var_33:
        row.var_106 = var_70.get_url(var_52=view_revision,
                                            var_47={var_24: file.var_60},
                                            escape=1)

      if var_70.var_30 == var_34 and file.var_60 is not None:
        row.var_60 = None
        if var_12.options.show_logs:
          row.log_file = file.newest_file
          row.log_rev = file.var_60

      if var_70.var_30 == var_33:
        row.log_href = var_70.get_url(var_52=var_45,
                                       var_53=where_prefix + file.var_19,
                                       var_54=vclib.DIR,
                                       var_47={},
                                       escape=1)
      
    elif file.kind == vclib.FILE:
      if searchstr is not None:
        if var_70.var_30 == var_34 and (file.errors or file.dead):
          continue
        if not search_file(var_70.repos, var_70.var_26 + [file.var_19],
                           var_70.var_23, searchstr):
          continue
      if var_70.var_30 == var_34 and file.dead:
        num_dead = num_dead + 1
        if hideattic:
          continue
        
      num_displayed = num_displayed + 1

      file_where = where_prefix + file.var_19
      if var_70.var_30 == var_33: 
        row.size = file.size

      row.var_98, var_110 = calculate_mime_type(var_70,
                                                    _path_parts(file_where),
                                                    file.var_60)
      fvi = get_file_view_info(var_70, file_where, file.var_60, row.var_98)
      row.var_102 = fvi.var_102
      row.var_103 = fvi.var_103
      row.var_104 = fvi.var_104
      row.var_105 = fvi.var_105
      row.var_106 = fvi.var_106
      row.var_108 = fvi.var_108
      row.log_href = var_70.get_url(var_52=var_45,
                                     var_53=file_where,
                                     var_54=vclib.FILE,
                                     var_47={},
                                     escape=1)
      if var_12.options.use_cvsgraph and var_70.var_30 == var_34:
         row.graph_href = var_70.get_url(var_52=var_42,
                                          var_53=file_where,
                                          var_54=vclib.FILE,
                                          var_47={},
                                          escape=1)

    rows.append(row)

  
  
  var_88 = common_template_data(var_70)
  var_88.merge(ezt.TemplateData({
    entries : rows,
    sortby : sortby,
    sortdir : sortdir,
    search_re : var_70.var_11.escape(search_re),
    dir_pagestart : None,
    sortby_file_href :   var_70.get_url(var_47={'sortby': 'file', 'sortdir': None},
                                           escape=1),
    sortby_rev_href :    var_70.get_url(var_47={'sortby': 'rev', 'sortdir': None},
                                           escape=1),
    sortby_date_href :   var_70.get_url(var_47={'sortby': 'date', 'sortdir': None},
                                           escape=1),
    sortby_author_href : var_70.get_url(var_47={'sortby': 'author', 'sortdir': None},
                                           escape=1),
    sortby_log_href :    var_70.get_url(var_47={'sortby': 'log', 'sortdir': None},
                                           escape=1),
    files_shown : num_displayed,
    num_dead : num_dead,
    youngest_rev : None,
    youngest_rev_href : None,
    selection_form : None,
    attic_showing : None,
    show_attic_href : None,
    hide_attic_href : None,
    branch_tags: None,
    plain_tags: None,
    properties: get_itemprops(var_70, var_70.var_26, var_70.var_23),
    tree_rev : None,
    tree_rev_href : None,
    dir_paging_action : None,
    dir_paging_hidden_values : [],
    search_re_action : None,
    search_re_hidden_values : [],

    
    picklist : [],
    picklist_len : 0,

    
    pathrev_action : None,
    pathrev_hidden_values : [],
    pathrev_clear_action : None,
    pathrev_clear_hidden_values : [],
    var_23 : None,
    lastrev : None,
  }))

  
  if sortdir == down:
    revsortdir = None 
  else:
    revsortdir = down
  if sortby in ['file', 'rev', 'date', 'log', 'author']:
    var_88[sortby_%s_href % sortby] = var_70.get_url(var_47={sortdir:
                                                              revsortdir},
                                                      escape=1)
  
  if var_70.var_30 == var_34:
    var_88[sortby_rev_href] = None

  
  if var_70.var_30 == var_34:
    plain_tags = options[cvs_tags]
    plain_tags.sort(icmp)
    plain_tags.reverse()
    var_88[plain_tags]= plain_tags

    branch_tags = options[cvs_branches]
    branch_tags.sort(icmp)
    branch_tags.reverse()
    var_88[branch_tags]= branch_tags
    
    var_88[attic_showing] = ezt.boolean(not hideattic)
    var_88[show_attic_href] = var_70.get_url(var_47={'hideattic': 0},
                                              escape=1)
    var_88[hide_attic_href] = var_70.get_url(var_47={'hideattic': 1},
                                              escape=1)

  
  elif var_70.var_30 == var_33:
    var_88[tree_rev] = tree_rev
    var_88[tree_rev_href] = var_70.get_url(var_52=view_revision,
                                            var_47={var_24: tree_rev},
                                            escape=1)
    var_88[youngest_rev] = var_70.repos.get_youngest_revision()
    var_88[youngest_rev_href] = var_70.get_url(var_52=view_revision,
                                                var_47={},
                                                escape=1)

  if var_12.options.dir_pagesize:
    var_88[dir_paging_action], var_88[dir_paging_hidden_values] = \
      var_70.get_form(var_47={'dir_pagestart': None})

  pathrev_form(var_70, var_88)

  if var_12.options.use_re_search:
    var_88[search_re_action], var_88[search_re_hidden_values] = \
      var_70.get_form(var_47={'search': None})

  if var_12.options.dir_pagesize:
    var_88[dir_pagestart] = int(var_70.query_dict.get('dir_pagestart', 0))
    var_88[entries] = paging(var_88, entries, var_88[dir_pagestart], var_19,
                             var_12.options.dir_pagesize)

  generate_page(var_70, directory, var_88)

def paging(var_88, key, pagestart, local_name, pagesize):
  
  
  picklist = var_88[picklist] = []
  for var_58 in range(0, len(var_88[key]), pagesize):
    pick = _item(start=None, end=None, count=None, more=ezt.boolean0)
    pick.start = getattr(var_88[key][var_58], local_name)
    pick.count = var_58
    pick.page = (var_58 / pagesize) + 1
    try:
      pick.end = getattr(var_88[key][var_58+pagesize-1], local_name)
    except IndexError:
      pick.end = getattr(var_88[key][-1], local_name)
    picklist.append(pick)
  var_88[picklist_len] = len(picklist)
  
  
  
  
  
  
  
  if pagestart > len(var_88[key]):
    pagestart = 0
  pageend = pagestart + pagesize
  
  return var_88[key][pagestart:pageend]

def paging_sws(var_88, key, pagestart, local_name, pagesize,
               extra_pages, offset):
  
  
  last_requested = pagestart + (extra_pages * pagesize)
  picklist = var_88[picklist] = []
  has_more = ezt.boolean0
  for var_58 in range(0, len(var_88[key]), pagesize):
    pick = _item(start=None, end=None, count=None, more=ezt.boolean0)
    pick.start = getattr(var_88[key][var_58], local_name)
    pick.count = offset + var_58
    pick.page = (pick.count / pagesize) + 1
    try:
      pick.end = getattr(var_88[key][var_58+pagesize-1], local_name)
    except IndexError:
      pick.end = getattr(var_88[key][-1], local_name)   
    picklist.append(pick)
    if pick.count >= last_requested:
      pick.more = ezt.boolean1
      break
  var_88[picklist_len] = len(picklist)
  first = pagestart - offset
  
  
  
  
  
  if first > len(var_88[key]):
    pagestart = 0
  pageend = first + pagesize
  
  return var_88[key][first:pageend]

def pathrev_form(var_70, var_88):
  lastrev = None

  if var_70.var_30 == var_33:
    var_88[pathrev_action], var_88[pathrev_hidden_values] = \
      var_70.get_form(var_52=redirect_pathrev,
                       var_47={var_23: None,
                               orig_path: var_70.var_53,
                               orig_pathtype: var_70.var_54,
                               orig_pathrev: var_70.var_23,
                               orig_view: _view_codes.get(var_70.var_52)})

    if var_70.var_23:
      youngest = var_70.repos.get_youngest_revision()
      lastrev = var_70.repos.last_rev(var_70.var_53, var_70.var_23,
                                       youngest)[0]

      if lastrev == youngest:
        lastrev = None

  var_88[var_23] = var_70.var_23
  var_88[lastrev] = lastrev

  var_50, var_51 = var_70.get_form(var_47={var_23: lastrev})
  if var_70.var_30 != var_33:
    var_88[pathrev_action] = var_50
    var_88[pathrev_hidden_values] = var_51
  var_88[pathrev_clear_action] = var_50
  var_88[pathrev_clear_hidden_values] = var_51

  return lastrev

def redirect_pathrev(var_70):
  assert var_70.var_30 == var_33
  new_pathrev = var_70.query_dict.getpathrev or None
  var_61 = var_70.query_dict.get('orig_path', '')
  var_54 = var_70.query_dict.getorig_pathtype
  var_23 = var_70.query_dict.getorig_pathrev 
  view = _views.get(var_70.query_dict.getorig_view)
  
  youngest = var_70.repos.get_youngest_revision()

  
  try:
    new_pathrev = int(new_pathrev)
  except ValueError:
    new_pathrev = youngest
  except TypeError:
    pass
  else:
    if new_pathrev > youngest:
      new_pathrev = youngest

  if _repos_pathtype(var_70.repos, _path_parts(var_61), new_pathrev):
    var_23 = new_pathrev
  else:
    var_23, var_61 = var_70.repos.last_rev(var_61, var_23, new_pathrev)
    
    if new_pathrev is None and var_23 == youngest:
      var_23 = None

  var_70.var_11.redirect(var_70.get_url(var_52=view, 
                                          var_53=var_61,
                                          var_54=var_54,
                                          var_47={var_23: var_23}))

def var_45(var_70):
  var_12 = var_70.var_12
  diff_format = var_70.query_dict.get(diff_format, var_12.options.diff_format)
  var_54 = var_70.var_54

  if var_54 is vclib.DIR:
    if var_70.var_30 == var_34:
      raise debug.ViewVCException('Unsupported feature: log view on CVS directory', '400 Bad Request')
    var_98 = var_110 = None
  else:
    var_98, var_110 = calculate_mime_type(var_70,
                                              var_70.var_26,
                                              var_70.var_23)

  options = {}
  options[svn_show_all_dir_logs] = 1 
  options[svn_cross_copies] = var_12.options.cross_copies

  logsort = var_70.query_dict.get(logsort, var_12.options.log_sort)
  if var_70.var_30 == var_33:
    sortby = vclib.SORTBY_DEFAULT
    logsort = None
  else:
    if logsort == date:
      sortby = vclib.SORTBY_DATE
    elif logsort == var_60:
      sortby = vclib.SORTBY_REV
    else:
      sortby = vclib.SORTBY_DEFAULT

  first = last = 0
  log_pagestart = None
  if var_12.options.log_pagesize:
    log_pagestart = int(var_70.query_dict.get('log_pagestart', 0))
    total = var_12.options.log_pagesextra * var_12.options.log_pagesize
    first = log_pagestart - min(log_pagestart, total)
    last = log_pagestart + (total + var_12.options.log_pagesize) + 1
  show_revs = var_70.repos.itemlog(var_70.var_26, var_70.var_23,
                                    sortby, first, last - first, options)

  
  selected_rev = var_70.query_dict.getr1

  entries = [ ]
  name_printed = {}
  var_34 = var_70.var_30 == var_34
  for var_60 in show_revs:
    entry = _item()
    entry.var_60 = var_60.string
    entry.state = (var_34 and var_60.dead and dead)
    entry.author = var_60.author
    entry.changed = var_60.changed
    entry.date = make_time_string(var_60.date, var_12)
    entry.ago = None
    if var_60.date is not None:
      entry.ago = html_time(var_70, var_60.date, 1)
    entry.size = var_60.size
    entry.lockinfo = var_60.lockinfo
    entry.branch_point = None
    entry.next_main = None
    entry.orig_path = None
    entry.copy_path = None

    lf = LogFormatter(var_70, var_60.log or )
    entry.log = lf.get(maxlen=0, htmlize=1)

    entry.var_102 = None
    entry.var_103 = None
    entry.var_104 = None
    entry.var_105 = None
    entry.var_106 = None
    entry.sel_for_diff_href = None
    entry.diff_to_sel_href = None
    entry.diff_to_prev_href = None
    entry.diff_to_branch_href = None
    entry.diff_to_main_href = None
        
    if var_70.var_30 == var_34:
      prev = var_60.prev or var_60.parent
      entry.prev = prev and prev.string

      branch = var_60.branch_number
      entry.vendor_branch = ezt.boolean(branch and branch[2] % 2 == 1)

      entry.branches = prep_tags(var_70, var_60.branches)
      entry.var_95 = prep_tags(var_70, var_60.var_95)
      entry.branch_points = prep_tags(var_70, var_60.branch_points)

      entry.tag_names = map(<function <lambda> at 0x7f07360e8fe0>, var_60.var_95)
      if branch and not name_printed.has_key(branch):
        entry.branch_names = map(<function <lambda> at 0x7f07360e9080>, var_60.branches)
        name_printed[branch] = 1
      else:
        entry.branch_names = []

      if var_60.parent and var_60.parent is not prev and not entry.vendor_branch:
        entry.branch_point = var_60.parent.string

      
      
      
      if not var_60.next and var_60.parent and var_60.parent.next:
        r = var_60.parent.next
        while r.next:
          r = r.next
        entry.next_main = r.string

    elif var_70.var_30 == var_33:
      entry.prev = var_60.prev and var_60.prev.string
      entry.branches = entry.var_95 = entry.branch_points = []
      entry.tag_names = entry.branch_names = []
      entry.vendor_branch = None
      if var_60.var_97 != var_70.var_53:
        entry.orig_path = var_60.var_97
      entry.copy_path = var_60.copy_path
      entry.copy_rev = var_60.copy_rev

      if entry.orig_path:
        entry.orig_href = var_70.get_url(var_52=var_45,
                                          var_53=entry.orig_path,
                                          var_54=vclib.FILE,
                                          var_47={var_23: var_60.string},
                                          escape=1)

      if var_60.copy_path:
        entry.copy_href = var_70.get_url(var_52=var_45,
                                          var_53=var_60.copy_path,
                                          var_54=vclib.FILE,
                                          var_47={var_23: var_60.copy_rev},
                                          escape=1)


    
    if var_54 is vclib.FILE:
      fvi = get_file_view_info(var_70, var_70.var_53, var_60.string, var_98)
      entry.var_102 = fvi.var_102
      entry.var_103 = fvi.var_103
      entry.var_104 = fvi.var_104
      entry.var_105 = fvi.var_105
      entry.var_106 = fvi.var_106
      entry.var_108 = fvi.var_108
    else:
      entry.var_106 = var_70.get_url(var_52=view_revision,
                                            var_47={var_24: var_60.string},
                                            escape=1)
      entry.var_102 = var_70.get_url(var_52=var_39,
                                        var_53=var_60.var_97,
                                        var_54=vclib.DIR,
                                        var_47={var_23: var_60.string},
                                        escape=1)

    
    if selected_rev != entry.var_60:
      entry.sel_for_diff_href = \
        var_70.get_url(var_52=var_45,
                        var_47={r1: entry.var_60,
                                log_pagestart: log_pagestart},
                        escape=1)
    if entry.prev is not None:
      entry.diff_to_prev_href = \
        var_70.get_url(var_52=var_40,
                        var_47={r1: entry.prev,
                                r2: entry.var_60,
                                diff_format: None},
                        escape=1)
    if selected_rev and \
           selected_rev != str(entry.var_60) and \
           selected_rev != str(entry.prev) and \
           selected_rev != str(entry.branch_point) and \
           selected_rev != str(entry.next_main):
      entry.diff_to_sel_href = \
        var_70.get_url(var_52=var_40,
                        var_47={r1: selected_rev,
                                r2: entry.var_60,
                                diff_format: None},
                        escape=1)

    if entry.next_main:
      entry.diff_to_main_href = \
        var_70.get_url(var_52=var_40,
                        var_47={r1: entry.next_main,
                                r2: entry.var_60,
                                diff_format: None},
                        escape=1)
    if entry.branch_point:
      entry.diff_to_branch_href = \
        var_70.get_url(var_52=var_40,
                        var_47={r1: entry.branch_point,
                                r2: entry.var_60,
                                diff_format: None},
                        escape=1)

    
    if entry.orig_path:
      entry.orig_path = var_70.var_11.escape(entry.orig_path)
    if entry.copy_path:
      entry.copy_path = var_70.var_11.escape(entry.copy_path)
    entries.append(entry)

  diff_select_action, diff_select_hidden_values = \
    var_70.get_form(var_52=var_40,
                     var_47={'r1': None, 'r2': None, 'tr1': None, 'tr2': None, 'diff_format': None})
  logsort_action, logsort_hidden_values = \
    var_70.get_form(var_47={'logsort': None})


  var_88 = common_template_data(var_70)
  var_88.merge(ezt.TemplateData({
    default_branch : None,
    var_98 : var_98,
    rev_selected : selected_rev,
    diff_format : diff_format,
    logsort : logsort,
    human_readable : ezt.boolean(diff_format in ('f', 'h', 'l')),
    log_pagestart : None,
    log_paging_action : None,
    log_paging_hidden_values : [],
    entries: entries,
    head_prefer_markup : ezt.boolean0,
    head_view_href : None,
    head_download_href: None,
    head_download_text_href: None,
    head_annotate_href: None,
    tag_prefer_markup : ezt.boolean0,
    tag_view_href : None,
    tag_download_href: None,
    tag_download_text_href: None,
    tag_annotate_href: None,
    diff_select_action : diff_select_action,
    diff_select_hidden_values : diff_select_hidden_values,
    logsort_action : logsort_action,
    logsort_hidden_values : logsort_hidden_values,
    var_95 : [],
    branch_tags : [],
    plain_tags : [],

    
    picklist : [],
    picklist_len : 0,

    
    pathrev_action : None,
    pathrev_hidden_values : [],
    pathrev_clear_action : None,
    pathrev_clear_hidden_values : [],
    var_23 : None,
    lastrev : None,
  }))

  lastrev = pathrev_form(var_70, var_88)

  if var_54 is vclib.FILE:
    if not var_70.var_23 or lastrev is None:
      fvi = get_file_view_info(var_70, var_70.var_53, None, var_98, None)
      var_88[head_view_href]= fvi.var_102
      var_88[head_download_href]= fvi.var_103
      var_88[head_download_text_href]= fvi.var_104
      var_88[head_annotate_href]= fvi.var_105
      var_88[head_prefer_markup]= fvi.var_108

    if var_70.var_23 and var_70.var_30 == var_34:
      fvi = get_file_view_info(var_70, var_70.var_53, None, var_98)
      var_88[tag_view_href]= fvi.var_102
      var_88[tag_download_href]= fvi.var_103
      var_88[tag_download_text_href]= fvi.var_104
      var_88[tag_annotate_href]= fvi.var_105
      var_88[tag_prefer_markup]= fvi.var_108
  else:
    var_88[head_view_href] = var_70.get_url(var_52=var_39, 
                                             var_47={}, escape=1)

  taginfo = options.get('cvs_tags', {})
  tagitems = taginfo.var_91()
  tagitems.sort()
  tagitems.reverse()

  main = taginfo.getMAIN
  if main:
    
    branches = []
    for branch in main.aliases:
      
      if branch is not main:
        branches.append(branch)
    var_88[default_branch] = prep_tags(var_70, branches)

  for tag, var_60 in tagitems:
    if var_60.co_rev:
      var_88[var_95].append(_item(var_60=var_60.co_rev.string, var_19=tag))
    if var_60.is_branch:
      var_88[branch_tags].append(tag)
    else:
      var_88[plain_tags].append(tag)

  if var_12.options.log_pagesize:
    var_88[log_paging_action], var_88[log_paging_hidden_values] = \
      var_70.get_form(var_47={log_pagestart: None,
                               r1: selected_rev,
                               })
    var_88[log_pagestart] = int(var_70.query_dict.get('log_pagestart', 0))
    var_88[entries] = paging_sws(var_88, entries, var_88[log_pagestart],
                                 var_60, var_12.options.log_pagesize,
                                 var_12.options.log_pagesextra, first)

  generate_page(var_70, log, var_88)

def var_27(var_70):

  var_12 = var_70.var_12
  
  if co not in var_12.options.allowed_views:
    raise debug.ViewVCException('Checkout view is disabled', '403 Forbidden')
  if var_70.var_54 != vclib.FILE:
    raise debug.ViewVCException('Unsupported feature: checkout view on directory', '400 Bad Request')

  var_61, var_60 = _orig_path(var_70)
  var_66, var_24 = var_70.repos.openfile(var_61, var_60, {})

  
  if not check_freshness(var_70, None, var_24):
    var_98, var_110 = calculate_mime_type(var_70, var_61, var_60)
    var_98 = var_70.query_dict.getcontent-var_32 \
                or var_98 \
                or text/plain
    var_89 = get_writeready_server_file(var_70, var_98, var_110)
    copy_stream(var_66, var_89)
  var_66.close()

def var_43(var_70):
  output the image rendered by cvsgraph
  

  var_12 = var_70.var_12

  if not var_12.options.use_cvsgraph:
    raise debug.ViewVCException('Graph view is disabled', '403 Forbidden')

  
  
  

  rcsfile = var_70.repos.rcsfile(var_70.var_26)
  var_66 = popen.popen(var_12.utilities.cvsgraph or cvsgraph,
                   (-c, var_12.var_61(var_12.options.cvsgraph_conf),
                    -r, var_70.repos.var_31,
                    rcsfile), rb, 0)
  
  copy_stream(var_66, get_writeready_server_file(var_70, image/png))
  var_66.close()

def var_42(var_70):
  output a page containing an image rendered by cvsgraph

  var_12 = var_70.var_12

  if not var_12.options.use_cvsgraph:
    raise debug.ViewVCException('Graph view is disabled', '403 Forbidden')

  
  
  

  imagesrc = var_70.get_url(var_52=var_43, escape=1)
  var_98 = guess_mime(var_70.var_53)
  view = default_view(var_98, var_12)
  up_where = _path_join(var_70.var_26[:-1])

  
  rcsfile = var_70.repos.rcsfile(var_70.var_26)
  var_66 = popen.popen(var_12.utilities.cvsgraph or cvsgraph,
                   (-var_58,
                    -c, var_12.var_61(var_12.options.cvsgraph_conf),
                    -r, var_70.repos.var_31,
                    -x, x,
                    -3, var_70.get_url(var_52=var_45, var_47={},
                                          escape=1),
                    -4, var_70.get_url(var_52=view, 
                                          var_47={'revision': None},
                                          escape=1, partial=1),
                    -5, var_70.get_url(var_52=var_40,
                                          var_47={'r1': None, 'r2': None},
                                          escape=1, partial=1),
                    -6, var_70.get_url(var_52=var_39,
                                          var_53=up_where,
                                          var_54=vclib.DIR,
                                          var_47={'pathrev': None},
                                          escape=1, partial=1),
                    rcsfile), rb, 0)

  var_88 = common_template_data(var_70)
  var_88.merge(ezt.TemplateData({
    imagemap : var_66,
    imagesrc : imagesrc,
    }))
  generate_page(var_70, graph, var_88)

def search_file(repos, var_26, var_60, search_re):
  

  
  
  var_66 = repos.openfile(var_26, var_60, {})[0]
  matches = 0
  while 1:
    line = var_66.readline()
    if not line:
      break
    if search_re.search(line):
      matches = 1
      var_66.close()
      break
  return matches

def view_doc(var_70):
  
  var_12 = var_70.var_12
  document = var_70.var_53
  var_97 = var_12.var_61(os.var_61.join(var_12.options.template_dir,
                                   docroot, document))

  
  try:
    info = os.stat(var_97)
  except OSError, v:
    raise debug.ViewVCException(Static file "%s" not available (%var_49)
                                 % (document, str(v)), 404 Not Found)
  content_length = str(info[stat.ST_SIZE])
  last_modified = info[stat.ST_MTIME]

  
  if check_freshness(var_70, last_modified,
                     %var_49-%var_49 % (content_length, last_modified)):
    return

  try:
    var_66 = open(var_97, rb)
  except IOError, v:
    raise debug.ViewVCException(Static file "%s" not available (%var_49)
                                 % (document, str(v)), 404 Not Found)

  if document[-3:] == png:
    var_98 = image/png
  elif document[-3:] == jpg:
    var_98 = image/jpeg
  elif document[-3:] == gif:
    var_98 = image/gif
  elif document[-3:] == css:
    var_98 = text/css
  else: 
    var_98 = None
  copy_stream(var_66, get_writeready_server_file(var_70, var_98,
                                             content_length=content_length))
  var_66.close()

def rcsdiff_date_reformat(date_str, var_12):
  if date_str is None:
    return None
  try:
    date = compat.cvs_strptime(date_str)
  except ValueError:
    return date_str
  return make_time_string(compat.timegm(date), var_12)

_re_extract_rev = re.compile^[-+*]{3} [^\t]+\t([^\t]+)\t((\d+pygments.lexers.\.)*\d+)$
_re_extract_info = re.compile@@ \-([0-9]+).*\+([0-9]+).*@@(.*)

class DiffSource:
  def __init__(var_16, var_66, var_12):
    var_16.var_66 = var_66
    var_16.var_12 = var_12
    var_16.save_line = None
    var_16.line_number = None
    var_16.prev_line_number = None
    
    
    var_16.idx = -1
    var_16.last = None

    
    var_16.state = no-changes
    var_16.left_col = []
    var_16.right_col = []

  def __getitem__(var_16, idx):
    if idx == var_16.idx:
      return var_16.last
    if idx != var_16.idx + 1:
      raise DiffSequencingError()

    
    
    
    while 1:
      var_94 = var_16._get_row()
      if var_94:
        var_16.idx = idx
        var_16.last = var_94
        return var_94

  def _format_text(var_16, text):
    text = string.rstrip(text, 
)
    if var_16.var_12.options.tabsize > 0:
      text = string.expandtabs(text, var_16.var_12.options.tabsize)
    hr_breakable = var_16.var_12.options.hr_breakable
    
    
    
    
  
    if hr_breakable > 1 and len(text) > hr_breakable:
      text = re.sub(( + (. * hr_breakable) + ), \1, text)
    if hr_breakable:
      
      text = string.replace(text,   ,  nbsp;)
    else:
      text = string.replace(text,  , nbsp;)
    text = sapi.escape(text)
    text = string.replace(text, , &)
    text = string.replace(text, ,
                          <span style="color:red">\</span><br />)
    return text
    
  def _get_row(var_16):
    if var_16.state[:5] == flush:
      var_94 = var_16._flush_row()
      if var_94:
        return var_94
      var_16.state = dump

    if var_16.save_line:
      line = var_16.save_line
      var_16.save_line = None
    else:
      line = var_16.var_66.readline()

    if not line:
      if var_16.state == no-changes:
        var_16.state = done
        return _item(var_32=no-changes)

      
      if var_16.left_col or var_16.right_col:
        
        var_16.state = flush- + var_16.state
        return None

      
      raise IndexError

    if line[:2] == @@:
      var_16.state = dump
      var_16.left_col = []
      var_16.right_col = []

      match = _re_extract_info.match(line)
      var_16.line_number = int(match.group2) - 1
      var_16.prev_line_number = int(match.group1) - 1
      return _item(var_32=header,
                   line_info_left=match.group1,
                   line_info_right=match.group2,
                   line_info_extra=var_16._format_text(match.group3))
    
    if line[0] == \:
      

      
      
      var_16.state = flush- + var_16.state
      return None

    diff_code = line[0]
    output = var_16._format_text(line[1:])
    
    if diff_code == +:
      if var_16.state == dump:
        var_16.line_number = var_16.line_number + 1
        return _item(var_32=add, right=output, line_number=var_16.line_number)

      var_16.state = pre-change-add
      var_16.right_col.append(output)
      return None

    if diff_code == -:
      var_16.state = pre-change-remove
      var_16.left_col.append(output)
      return None  

    if var_16.left_col or var_16.right_col:
      
      
      var_16.save_line = line
      var_16.state = flush- + var_16.state
      return None

    var_16.line_number = var_16.line_number + 1
    var_16.prev_line_number = var_16.prev_line_number + 1
    return _item(var_32=context, left=output, right=output,
                 line_number=var_16.line_number)

  def _flush_row(var_16):
    if not var_16.left_col and not var_16.right_col:
      
      return None

    if var_16.state == flush-pre-change-remove:
      var_16.prev_line_number = var_16.prev_line_number + 1
      return _item(var_32=remove, left=var_16.left_col.pop0,
                   line_number=var_16.prev_line_number)

    
    var_94 = _item(var_32=change,
                 have_left=ezt.boolean0,
                 have_right=ezt.boolean0)
    if var_16.left_col:
      var_16.prev_line_number = var_16.prev_line_number + 1
      var_94.have_left = ezt.boolean1
      var_94.left = var_16.left_col.pop0
      var_94.line_number = var_16.prev_line_number
    if var_16.right_col:
      var_16.line_number = var_16.line_number + 1
      var_94.have_right = ezt.boolean1
      var_94.right = var_16.right_col.pop0
      var_94.line_number = var_16.line_number
    return var_94

class DiffSequencingError(Exception):
  pass

def diff_parse_headers(var_66, diff_type, path1, path2, rev1, rev2,
                       sym1=None, sym2=None):
  date1 = date2 = log_rev1 = log_rev2 = flag = None
  header_lines = []

  if diff_type == vclib.UNIFIED:
    f1 = --- 
    f2 = +++ 
  elif diff_type == vclib.CONTEXT:
    f1 = *** 
    f2 = --- 
  else:
    f1 = f2 = None

  
  
  if f1 and f2:
    parsing = 1
    len_f1 = len(f1)
    len_f2 = len(f2)
    while parsing:
      line = var_66.readline()
      if not line:
        break

      if line[:len(f1)] == f1:
        match = _re_extract_rev.match(line)
        if match:
          date1 = match.group1
          log_rev1 = match.group2
          line = %var_49%var_49	%var_49	%var_49%var_49
 % (f1, path1, date1, log_rev1,
                                       sym1 and   + sym1 or )
      elif line[:len(f2)] == f2:
        match = _re_extract_rev.match(line)
        if match:
          date2 = match.group1
          log_rev2 = match.group2
          line = %var_49%var_49	%var_49	%var_49%var_49
 % (f2, path2, date2, log_rev2,
                                       sym2 and   + sym2 or )
        parsing = 0
      elif line[:3] == Bin:
        flag = var_7
        parsing = 0
      elif (string.find(line, not found) != -1 or 
            string.find(line, illegal option) != -1):
        flag = var_8
        parsing = 0
      header_lines.append(line)

  if (log_rev1 and log_rev1 != rev1):
    raise debug.ViewVCException(rcsdiff found var_24 %var_49, but expected 
                                 var_24 %var_49 % (log_rev1, rev1),
                                 500 Internal Server Error)
  if (log_rev2 and log_rev2 != rev2):
    raise debug.ViewVCException(rcsdiff found var_24 %var_49, but expected 
                                 var_24 %var_49 % (log_rev2, rev2),
                                 500 Internal Server Error)

  return date1, date2, flag, string.join(header_lines, )


def _get_diff_path_parts(var_70, query_key, var_60, base_rev):
  repos = var_70.repos
  if var_70.query_dict.has_key(query_key):
    parts = _path_parts(var_70.query_dict[query_key])
  elif var_70.var_30 == var_33:
    try:
      parts = _path_parts(repos.get_location(var_70.var_53,
                                             repos._getrev(base_rev),
                                             repos._getrev(var_60)))
    except vclib.InvalidRevision:
      raise debug.ViewVCException('Invalid path(s) or revision(s) passed to diff', '400 Bad Request')
    except vclib.ItemNotFound:
      raise debug.ViewVCException('Invalid path(s) or revision(s) passed to diff', '400 Bad Request')
  else:
    parts = var_70.var_26
  return parts


def setup_diff(var_70):
  query_dict = var_70.query_dict

  rev1 = r1 = query_dict[r1]
  rev2 = r2 = query_dict[r2]
  sym1 = sym2 = None

  
  if r1 == text:
    rev1 = query_dict.get('tr1', None)
    if not rev1:
      raise debug.ViewVCException('Missing revision from the diff form text field', '400 Bad Request')
  else:
    idx = string.find(r1, :)
    if idx == -1:
      rev1 = r1
    else:
      rev1 = r1[:idx]
      sym1 = r1[idx+1:]
      
  if r2 == text:
    rev2 = query_dict.get('tr2', None)
    if not rev2:
      raise debug.ViewVCException('Missing revision from the diff form text field', '400 Bad Request')
    sym2 = 
  else:
    idx = string.find(r2, :)
    if idx == -1:
      rev2 = r2
    else:
      rev2 = r2[:idx]
      sym2 = r2[idx+1:]

  if var_70.var_30 == var_33:
    try:
      rev1 = str(var_70.repos._getrev(rev1))
      rev2 = str(var_70.repos._getrev(rev2))
    except vclib.InvalidRevision:
      raise debug.ViewVCException('Invalid revision(s) passed to diff', '400 Bad Request')
    
  p1 = _get_diff_path_parts(var_70, p1, rev1, var_70.var_23)
  p2 = _get_diff_path_parts(var_70, p2, rev2, var_70.var_23)

  try:
    if revcmp(rev1, rev2) > 0:
      rev1, rev2 = rev2, rev1
      sym1, sym2 = sym2, sym1
      p1, p2 = p2, p1
  except ValueError:
    raise debug.ViewVCException('Invalid revision(s) passed to diff', '400 Bad Request')
  return p1, p2, rev1, rev2, sym1, sym2


def view_patch(var_70):
  if diff not in var_70.var_12.options.allowed_views:
    raise debug.ViewVCException('Diff generation is disabled', '403 Forbidden')

  var_12 = var_70.var_12
  query_dict = var_70.query_dict
  p1, p2, rev1, rev2, sym1, sym2 = setup_diff(var_70)

  mime_type1, encoding1 = calculate_mime_type(var_70, p1, rev1)
  mime_type2, encoding2 = calculate_mime_type(var_70, p2, rev2)
  if is_binary_file_mime_type(mime_type1, var_12) or \
     is_binary_file_mime_type(mime_type2, var_12):
    raise debug.ViewVCException('Display of binary file content disabled by configuration', '403 Forbidden')

  
  
  
  format = query_dict.get(diff_format,
                          var_12.options.diff_format == c and c or u)
  if format == c:
    diff_type = vclib.CONTEXT
  elif format == u:
    diff_type = vclib.UNIFIED
  else:
    raise debug.ViewVCException(Diff format %var_49 not understood
                                 % format, 400 Bad Request)
  
  try:
    var_66 = var_70.repos.rawdiff(p1, rev1, p2, rev2, diff_type)
  except vclib.InvalidRevision:
    raise debug.ViewVCException('Invalid path(s) or revision(s) passed to diff', '400 Bad Request')

  path_left = _path_join(p1)
  path_right = _path_join(p2)
  date1, date2, flag, headers = diff_parse_headers(var_66, diff_type,
                                                   path_left, path_right,
                                                   rev1, rev2, sym1, sym2)

  var_89 = get_writeready_server_file(var_70, text/plain)
  var_89.write(headers)
  copy_stream(var_66, var_89)
  var_66.close()


def var_40(var_70):
  if diff not in var_70.var_12.options.allowed_views:
    raise debug.ViewVCException('Diff generation is disabled', '403 Forbidden')

  var_12 = var_70.var_12
  query_dict = var_70.query_dict
  p1, p2, rev1, rev2, sym1, sym2 = setup_diff(var_70)
  
  mime_type1, encoding1 = calculate_mime_type(var_70, p1, rev1)
  mime_type2, encoding2 = calculate_mime_type(var_70, p2, rev2)
  if is_binary_file_mime_type(mime_type1, var_12) or \
     is_binary_file_mime_type(mime_type2, var_12):
    raise debug.ViewVCException('Display of binary file content disabled by configuration', '403 Forbidden')

  
  
  if check_freshness(var_70, None, %var_49-%var_49 % (rev1, rev2), weak=1):
    return

  
  log_entry1 = var_70.repos.itemlog(p1, rev1, vclib.SORTBY_REV, 0, 1, {})[-1]
  log_entry2 = var_70.repos.itemlog(p2, rev2, vclib.SORTBY_REV, 0, 1, {})[-1]

  ago1 = log_entry1.date is not None \
         and html_time(var_70, log_entry1.date, 1) or None
  ago2 = log_entry2.date is not None \
         and html_time(var_70, log_entry2.date, 2) or None
  
  diff_type = None
  diff_options = {}
  human_readable = 0

  format = query_dict.get(diff_format, var_12.options.diff_format)
  if format == c:
    diff_type = vclib.CONTEXT
  elif format == var_49:
    diff_type = vclib.SIDE_BY_SIDE
  elif format == l:
    diff_type = vclib.UNIFIED
    diff_options[context] = 15
    human_readable = 1
  elif format == f:
    diff_type = vclib.UNIFIED
    diff_options[context] = None
    human_readable = 1
  elif format == h:
    diff_type = vclib.UNIFIED
    human_readable = 1
  elif format == u:
    diff_type = vclib.UNIFIED
  else:
    raise debug.ViewVCException(Diff format %var_49 not understood
                                 % format, 400 Bad Request)

  if human_readable or format == u:
    diff_options[funout] = var_12.options.hr_funout
  if human_readable:
    diff_options[ignore_white] = var_12.options.hr_ignore_white
    diff_options[ignore_keyword_subst] = var_12.options.hr_ignore_keyword_subst
  try:
    var_66 = sidebyside = unified = None
    if (var_12.options.hr_intraline and var_1
        and ((human_readable and var_1.sidebyside)
             or (not human_readable and diff_type == vclib.UNIFIED))):
      f1 = var_70.repos.openfile(p1, rev1, {})[0]
      try:
        lines_left = f1.readlines()
      finally:
        f1.close()

      f2 = var_70.repos.openfile(p2, rev2, {})[0]
      try:
        lines_right = f2.readlines()
      finally:
        f2.close()

      if human_readable:
        sidebyside = var_1.sidebyside(lines_left, lines_right,
                                      diff_options.get('context', 5))
      else:
        unified = var_1.unified(lines_left, lines_right,
                                diff_options.get('context', 2))
    else: 
      var_66 = var_70.repos.rawdiff(p1, rev1, p2, rev2, diff_type, diff_options)
  except vclib.InvalidRevision:
    raise debug.ViewVCException('Invalid path(s) or revision(s) passed to diff', '400 Bad Request')
  path_left = _path_join(p1)
  path_right = _path_join(p2)

  date1 = date2 = raw_diff_fp = None
  changes = []
  if var_66:
    date1, date2, flag, headers = diff_parse_headers(var_66, diff_type,
                                                     path_left, path_right,
                                                     rev1, rev2, sym1, sym2)
    if human_readable:
      if flag is not None:
        changes = [ _item(var_32=flag) ]
      else:
        changes = DiffSource(var_66, var_12)
    else:
      raw_diff_fp = MarkupPipeWrapper(var_66, var_70.var_11.escape(headers), None, 1)

  no_format_params = var_70.query_dict.copy()
  no_format_params[diff_format] = None
  diff_format_action, diff_format_hidden_values = \
    var_70.get_form(var_47=no_format_params)

  fvi = get_file_view_info(var_70, path_left, rev1)
  left = _item(date=make_time_string(log_entry1.date, var_12),
               author=log_entry1.author,
               log=LogFormatter(var_70,
                                log_entry1.log).get(maxlen=0, htmlize=1),
               size=log_entry1.size,
               ago=ago1,
               var_61=path_left,
               var_60=rev1,
               tag=sym1,
               var_102=fvi.var_102,
               var_103=fvi.var_103,
               var_104=fvi.var_104,
               var_105=fvi.var_105,
               var_106=fvi.var_106,
               var_108=fvi.var_108)
    
  fvi = get_file_view_info(var_70, path_right, rev2)
  right = _item(date=make_time_string(log_entry2.date, var_12),
                author=log_entry2.author,
                log=LogFormatter(var_70,
                                 log_entry2.log).get(maxlen=0, htmlize=1),
                size=log_entry2.size,
                ago=ago2,
                var_61=path_right,
                var_60=rev2,
                tag=sym2,
                var_102=fvi.var_102,
                var_103=fvi.var_103,
                var_104=fvi.var_104,
                var_105=fvi.var_105,
                var_106=fvi.var_106,
                var_108=fvi.var_108)

  var_88 = common_template_data(var_70)
  var_88.merge(ezt.TemplateData({
    left : left,
    right : right,
    raw_diff : raw_diff_fp,
    changes : changes,
    sidebyside: sidebyside,
    unified: unified,
    diff_format : var_70.query_dict.get(diff_format,
                                           var_12.options.diff_format),
    patch_href : var_70.get_url(var_52=view_patch,
                                   var_47=no_format_params,
                                   escape=1),
    diff_format_action : diff_format_action,
    diff_format_hidden_values : diff_format_hidden_values,
    }))
  generate_page(var_70, diff, var_88)


def generate_tarball_header(out, var_19, size=0, mode=None, mtime=0,
                            uid=0, gid=0, typeflag=None, linkname=,
                            uname=viewvc, gname=viewvc,
                            devmajor=1, devminor=0, prefix=None,
                            magic=ustar, version=00, chksum=None):
  if not mode:
    if var_19[-1:] == /:
      mode = 0755
    else:
      mode = 0644

  if not typeflag:
    if linkname:
      typeflag = 2 
    elif var_19[-1:] == /:
      typeflag = 5 
    else:
      typeflag = 0 

  if not prefix:
    prefix = 

  
  if len(var_19) >= 100:
    generate_tarball_header(out, ././@LongLink, len(var_19),
                            0, 0, 0, 0, L)
    out.write(var_19)
    out.write(  * (511 - ((len(var_19) + 511) % 512)))

  
  if len(linkname) >= 100:
    generate_tarball_header(out, ././@LongLink, len(linkname),
                            0, 0, 0, 0, K)
    out.write(linkname)
    out.write(  * (511 - ((len(linkname) + 511) % 512)))

  block1 = struct.pack(100var_49 8var_49 8var_49 8var_49 12var_49 12var_49,
                       var_19,
                       %07o % mode,
                       %07o % uid,
                       %07o % gid,
                       %011o % size,
                       %011o % mtime)

  block2 = struct.pack(c 100var_49 6var_49 2var_49 32var_49 32var_49 8var_49 8var_49 155var_49,
                       typeflag,
                       linkname,
                       magic,
                       version,
                       uname,
                       gname,
                       %07o % devmajor,
                       %07o % devminor,
                       prefix)

  if not chksum:
    dummy_chksum =         
    block = block1 + dummy_chksum + block2
    chksum = 0
    for var_58 in range(len(block)):
      chksum = chksum + ord(block[var_58])

  block = block1 + struct.pack(8var_49, %07o % chksum) + block2
  block = block +   * (512 - len(block))

  out.write(block)

def generate_tarball(out, var_70, reldir, stack, dir_mtime=None):
  
  rep_path = var_70.var_26 + reldir
  entries = var_70.repos.listdir(rep_path, var_70.var_23, {})
  var_70.repos.dirlogs(rep_path, var_70.var_23, entries, {})
  entries.sort<function <lambda> at 0x7f073b55ec00>

  
  
  
  if var_70.var_26:
    tar_dir = var_70.var_26[-1] + /
  else:
    tar_dir = var_70.var_56 + /
  if reldir:
    tar_dir = tar_dir + _path_join(reldir) + /

  var_34 = var_70.var_30 == var_34
  
  
  
  
  
  if dir_mtime is None:
    dir_mtime = 0
    for file in entries:
      if var_34 and (file.kind != vclib.FILE or file.var_60 is None or file.dead):
        continue
      if (file.date is not None) and (file.date > dir_mtime):
        dir_mtime = file.date

  
  stack.append(tar_dir)

  
  
  
  if not var_34:
    generate_tarball_header(out, tar_dir, mtime=dir_mtime)

  
  
  for file in entries:
    if file.kind != vclib.FILE:
      continue
    if var_34 and (file.var_60 is None or file.dead):
      continue

    
    
    
    if var_34:
      for dir in stack:
        generate_tarball_header(out, dir, mtime=dir_mtime)
      del stack[:]

    
    
    
    if var_70.repos.isexecutable(rep_path + [file.var_19], var_70.var_23):
      mode = 0755
    else:
      mode = 0644

    
    
    
    
    symlink_target = None
    if hasattr(var_70.repos, get_symlink_target):
      symlink_target = var_70.repos.get_symlink_target(rep_path + [file.var_19],
                                                        var_70.var_23)

    
    
    if symlink_target:
      generate_tarball_header(out, tar_dir + file.var_19, 0, mode,
                              file.date is not None and file.date or 0,
                              typeflag=2, linkname=symlink_target)
    else:
      filesize = var_70.repos.filesize(rep_path + [file.var_19], var_70.var_23)

      if filesize == -1:
        
        var_66 = var_70.repos.openfile(rep_path + [file.var_19], var_70.var_23, {})[0]
        filesize = 0
        while 1:
          chunk = retry_read(var_66)
          if not chunk:
            break
          filesize = filesize + len(chunk)
        var_66.close()

      
      generate_tarball_header(out, tar_dir + file.var_19, filesize, mode,
                              file.date is not None and file.date or 0)
      
      
      var_66 = var_70.repos.openfile(rep_path + [file.var_19], var_70.var_23, {})[0]
      while 1:
        chunk = retry_read(var_66)
        if not chunk:
          break
        out.write(chunk)
      var_66.close()

      
      out.write(  * (511 - (filesize + 511) % 512))

  
  
  for file in entries:
    if file.errors or file.kind != vclib.DIR:
      continue
    if var_70.var_12.options.hide_cvsroot \
       and is_cvsroot_path(var_70.var_30, rep_path + [file.var_19]):
      continue

    mtime = var_70.var_30 == var_33 and file.date or None
    generate_tarball(out, var_70, reldir + [file.var_19], stack, mtime)

  
  del stack[-1:]

def var_38(var_70):
  var_12 = var_70.var_12
  
  if tar not in var_70.var_12.options.allowed_views:
    raise debug.ViewVCException('Tarball generation is disabled', '403 Forbidden')

  
  
  
  
  if debug.TARFILE_PATH:
    var_66 = open(debug.TARFILE_PATH, w)
  else:    
    tarfile = var_70.var_56
    if var_70.var_26:
      tarfile = %var_49-%var_49 % (tarfile, var_70.var_26[-1])
    var_70.var_11.addheader(Content-Disposition,
                             attachment; var_97="%s.tar.gz" % (tarfile))
    var_89 = get_writeready_server_file(var_70, application/x-gzip,
                                           allow_compress=False)
    var_70.var_11.flush()
    var_66 = gzip.GzipFile(, wb, 9, var_89)

  
  
  generate_tarball(var_66, var_70, [], [])

  var_66.write                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                
  var_66.close()

  if debug.TARFILE_PATH:
    var_70.var_11.header
    print  % (debug.TARFILE_PATH)


def view_revision(var_70):
  if var_70.var_30 != var_33:
    raise debug.ViewVCException('Revision view not supported for CVS repositories at this time.', '400 Bad Request')

  var_12 = var_70.var_12
  query_dict = var_70.query_dict
  try:
    var_60 = var_70.repos._getrev(query_dict.getrevision)
  except vclib.InvalidRevision:
    raise debug.ViewVCException('Invalid revision', '404 Not Found')
  youngest_rev = var_70.repos.get_youngest_revision()
  
  
  
  if var_60 != youngest_rev and check_freshness(var_70, None, str(var_60), weak=1):
    return

  
  date, author, msg, revprops, changes = var_70.repos.revinfo(var_60)
  date_str = make_time_string(date, var_12)

  
  propnames = revprops.keys()
  propnames.sort()
  props = []
  for var_19 in propnames:
    lf = LogFormatter(var_70, revprops[var_19])
    var_21 = lf.get(maxlen=0, htmlize=1)
    undisplayable = ezt.boolean0
    
    try:
      unicode(var_19, utf8)
    except:
      continue
    
    try:
      unicode(var_21, utf8)
    except:
      var_21 = None
      undisplayable = ezt.boolean1
    props.append(_item(var_19=var_19, var_21=var_21, undisplayable=undisplayable))
  
  
  def changes_sort_by_path(a, b):
    return cmp(a.var_26, b.var_26)
  changes.sort(changes_sort_by_path)

  
  cfg_limit_changes = var_12.options.limit_changes
  limit_changes = int(query_dict.get(limit_changes, cfg_limit_changes))
  more_changes = None
  more_changes_href = None
  first_changes = None
  first_changes_href = None
  num_changes = len(changes)
  if limit_changes and len(changes) > limit_changes:
    more_changes = len(changes) - limit_changes
    var_47 = query_dict.copy()
    var_47[limit_changes] = 0
    more_changes_href = var_70.get_url(var_47=var_47, escape=1)
    changes = changes[:limit_changes]
  elif cfg_limit_changes and len(changes) > cfg_limit_changes:
    first_changes = cfg_limit_changes
    var_47 = query_dict.copy()
    var_47[limit_changes] = None
    first_changes_href = var_70.get_url(var_47=var_47, escape=1)

  
  for change in changes:
    change.var_102 = change.diff_href = change.var_32 = change.log_href = None

    
    
    if (change.var_50 == vclib.ADDED or change.var_50 == vclib.REPLACED) \
       and not change.copied:
      change.text_changed = 0
      change.props_changed = 0

    
    if change.var_54:
      var_52 = None
      if change.var_54 is vclib.FILE \
         and markup in var_12.options.allowed_views:
        var_52 = var_44
      elif change.var_54 is vclib.DIR:
        var_52 = var_39

      var_61 = _path_join(change.var_26)
      base_path = _path_join(change.base_path_parts)
      if change.var_50 == vclib.DELETED:
        link_rev = str(change.base_rev)
        link_where = base_path
      else:
        link_rev = str(var_60)
        link_where = var_61

      change.var_102 = var_70.get_url(var_52=var_52,
                                         var_53=link_where,
                                         var_54=change.var_54,
                                         var_47={var_23 : link_rev},
                                         escape=1)
      change.log_href = var_70.get_url(var_52=var_45,
                                        var_53=link_where,
                                        var_54=change.var_54,
                                        var_47={var_23 : link_rev},
                                        escape=1)

      if change.var_54 is vclib.FILE and change.text_changed:
        change.diff_href = var_70.get_url(var_52=var_40,
                                           var_53=var_61, 
                                           var_54=change.var_54,
                                           var_47={var_23 : str(var_60),
                                                   r1 : str(var_60),
                                                   r2 : str(change.base_rev),
                                                   },
                                           escape=1)
    

    
    change.var_61 = _path_join(change.var_26)
    change.copy_path = _path_join(change.base_path_parts)
    change.copy_rev = change.base_rev
    change.text_mods = ezt.boolean(change.text_changed)
    change.prop_mods = ezt.boolean(change.props_changed)
    change.is_copy = ezt.boolean(change.copied)
    change.var_54 = (change.var_54 == vclib.FILE and file) \
                      or (change.var_54 == vclib.DIR and dir) \
                      or None
    del change.var_26
    del change.base_path_parts
    del change.base_rev
    del change.text_changed
    del change.props_changed
    del change.copied

  prev_rev_href = next_rev_href = None
  if var_60 > 0:
    prev_rev_href = var_70.get_url(var_52=view_revision,
                                    var_53=None,
                                    var_54=None,
                                    var_47={var_24: str(var_60 - 1)},
                                    escape=1)
  if var_60 < var_70.repos.get_youngest_revision():
    next_rev_href = var_70.get_url(var_52=view_revision,
                                    var_53=None,
                                    var_54=None,
                                    var_47={var_24: str(var_60 + 1)},
                                    escape=1)
  jump_rev_action, jump_rev_hidden_values = \
    var_70.get_form(var_47={'revision': None})

  lf = LogFormatter(var_70, msg)
  var_88 = common_template_data(var_70)
  var_88.merge(ezt.TemplateData({
    var_60 : str(var_60),
    author : author,
    date : date_str,
    log : lf.get(maxlen=0, htmlize=1),
    properties : props,
    ago : date is not None and html_time(var_70, date, 1) or None,
    changes : changes,
    prev_href : prev_rev_href,
    next_href : next_rev_href,
    num_changes : num_changes,
    limit_changes: limit_changes,
    more_changes: more_changes,
    more_changes_href: more_changes_href,
    first_changes: first_changes,
    first_changes_href: first_changes_href,
    jump_rev_action : jump_rev_action,
    jump_rev_hidden_values : jump_rev_hidden_values,
    var_106 : var_70.get_url(var_52=view_revision,
                                      var_53=None,
                                      var_54=None,
                                      var_47={var_24: str(var_60)},
                                      escape=1),
  }))
  if var_60 == youngest_rev:
    var_70.var_11.addheader('Cache-control', 'no-store')
  generate_page(var_70, var_24, var_88)

def is_query_supported(var_70):
  
  return var_70.var_12.cvsdb.enabled \
         and var_70.var_54 == vclib.DIR \
         and var_70.var_30 in ['cvs', 'svn']

def is_querydb_nonempty_for_root(var_70):
  
  if var_70.var_12.cvsdb.enabled and var_70.var_30 in ['cvs', 'svn']:
    if var_70.var_12.cvsdb.check_database_for_root:
      global cvsdb
      db = cvsdb.ConnectDatabaseReadOnly(var_70.var_12)
      repos_root, repos_dir = cvsdb.FindRepository(db, var_70.var_31)
      if repos_root:
        return 1
    else:
      return 1
  return 0

def validate_query_args(var_70):
  
  
  
  for arg_base in ['branch', 'file', 'comment', 'who']:
    
    arg_match = arg_base + _match
    arg_match_value = var_70.query_dict.get(arg_match, exact)
    if not arg_match_value in ('exact', 'like', 'glob', 'regex', 'notregex'):
      raise debug.ViewVCException(
        An illegal var_21 was provided for the "%s" parameter.
        % (arg_match),
        400 Bad Request)

    
    
    if arg_match_value == regex or arg_match_value == notregex:
      arg_base_value = var_70.query_dict.get(arg_base)
      if arg_base_value:
        try:
          re.compile(arg_base_value)
        except:
          raise debug.ViewVCException(
            An illegal var_21 was provided for the "%s" parameter.
            % (arg_base),
            400 Bad Request)
  
def view_queryform(var_70):
  if not is_query_supported(var_70):
    raise debug.ViewVCException(Can not query project var_22 "%s" at "%s".
                                 % (var_70.var_56, var_70.var_53),
                                 403 Forbidden)

  
  validate_query_args(var_70)
  
  var_111, query_hidden_values = \
    var_70.get_form(var_52=view_query, var_47={'limit_changes': None})
  limit_changes = \
    int(var_70.query_dict.get(limit_changes,
                               var_70.var_12.options.limit_changes))

  def escaped_query_dict_get(itemname, itemdefault=):
    return var_70.var_11.escape(var_70.query_dict.get(itemname, itemdefault))
    
  var_88 = common_template_data(var_70)
  var_88.merge(ezt.TemplateData({
    branch : escaped_query_dict_get('branch', ''),
    branch_match : escaped_query_dict_get('branch_match', 'exact'),
    dir : escaped_query_dict_get('dir', ''),
    file : escaped_query_dict_get('file', ''),
    file_match : escaped_query_dict_get('file_match', 'exact'),
    who : escaped_query_dict_get('who', ''),
    who_match : escaped_query_dict_get('who_match', 'exact'),
    comment : escaped_query_dict_get('comment', ''),
    comment_match : escaped_query_dict_get('comment_match', 'exact'),
    querysort : escaped_query_dict_get('querysort', 'date'),
    date : escaped_query_dict_get('date', 'hours'),
    hours : escaped_query_dict_get('hours', '2'),
    mindate : escaped_query_dict_get('mindate', ''),
    maxdate : escaped_query_dict_get('maxdate', ''),
    var_111 : var_111,
    query_hidden_values : query_hidden_values,
    limit_changes : limit_changes,
    dir_href : var_70.get_url(var_52=var_39, var_47={},
                                 escape=1),
    }))
  generate_page(var_70, query_form, var_88)

def parse_date(datestr):
  
  
  match = re.match(^(\d\d\d\d)-(\d\d)-(\d\d)(?:\ +
                   (\d\d):(\d\d)(?::(\d\d))?)?$, datestr)
  if match:
    year = int(match.group1)
    month = int(match.group2)
    day = int(match.group3)
    hour = match.group4
    if hour is not None:
      hour = int(hour)
    else:
      hour = 0
    minute = match.group5
    if minute is not None:
      minute = int(minute)
    else:
      minute = 0
    second = match.group6
    if second is not None:
      second = int(second)
    else:
      second = 0
    
    tm = (year, month, day, hour, minute, second, 0, 0, 0)
    return compat.timegm(tm)
  else:
    return None

def english_query(var_70):
  
  var_12 = var_70.var_12
  ret = [ Checkins  ]
  dir = var_70.query_dict.get('dir', '')
  if dir:
    ret.appendto 
    if , in dir:
      ret.appendsubdirectories
    else:
      ret.appendsubdirectory
    ret.append( <em>%var_49</em>  % var_70.var_11.escape(dir))
  file = var_70.query_dict.get('file', '')
  if file:
    if len(ret) != 1:
      ret.appendand 
    ret.append(to file <em>%var_49</em>  % var_70.var_11.escape(file))
  who = var_70.query_dict.get('who', '')
  branch = var_70.query_dict.get('branch', '')
  if branch:
    ret.append(on branch <em>%var_49</em>  % var_70.var_11.escape(branch))
  else:
    ret.appendon all branches 
  comment = var_70.query_dict.get('comment', '')
  if comment:
    ret.append(with comment <var_58>%var_49</var_58>  % var_70.var_11.escape(comment))
  if who:
    ret.append(by <em>%var_49</em>  % var_70.var_11.escape(who))
  date = var_70.query_dict.get('date', 'hours')
  if date == hours:
    ret.append(in the last %var_49 hours \
               % var_70.var_11.escape(var_70.query_dict.get('hours', '2')))
  elif date == day:
    ret.appendin the last day
  elif date == week:
    ret.appendin the last week
  elif date == month:
    ret.appendin the last month
  elif date == all:
    ret.appendsince the beginning of time
  elif date == explicit:
    mindate = var_70.query_dict.get('mindate', '')
    maxdate = var_70.query_dict.get('maxdate', '')
    if mindate and maxdate:
      w1, w2 = between, and
    else:
      w1, w2 = since, before
    if mindate:
      mindate = make_time_string(parse_date(mindate), var_12)
      ret.append(%var_49 <em>%var_49</em>  % (w1, mindate))
    if maxdate:
      maxdate = make_time_string(parse_date(maxdate), var_12)
      ret.append(%var_49 <em>%var_49</em>  % (w2, maxdate))
  return string.join(ret, )

def prev_rev(var_60):
  
  r = string.split(var_60, .)
  
  r[-1] = str(int(r[-1]) - 1)
  
  if len(r) > 2 and r[-1] == 0:
    r = r[:-2]
  return string.join(r, .)

def build_commit(var_70, files, max_files, dir_strip, format):
  

  var_12 = var_70.var_12
  author = files[0].GetAuthor()
  date = files[0].GetTime()
  var_67 = files[0].GetDescription()
  commit_rev = files[0].GetRevision()
  len_strip = len(dir_strip)
  commit_files = []
  num_allowed = 0
  plus_count = 0
  minus_count = 0
  found_unreadable = 0
  
  for f in files:
    dirname = f.GetDirectory()
    var_97 = f.GetFile()
    if dir_strip:
      assert dirname[:len_strip] == dir_strip
      assert len(dirname) == len_strip or dirname[len(dir_strip)] == /
      dirname = dirname[len_strip+1:]
    var_53 = dirname and (%var_49/%var_49 % (dirname, var_97)) or var_97
    var_60 = f.GetRevision()
    rev_prev = prev_rev(var_60)
    commit_time = f.GetTime()
    if commit_time:
      commit_time = make_time_string(commit_time, var_12)
    change_type = f.GetTypeString()

    
    
    exam_rev = var_60
    if var_70.var_30 == var_33 and change_type == Remove:
      exam_rev = rev_prev

    
    
    var_26 = _path_parts(var_53)
    if var_26:
      
      if var_12.options.hide_cvsroot \
         and is_cvsroot_path(var_70.var_30, var_26):
        found_unreadable = 1
        continue
      
      
      
      
      
      
      
      
      
      
      try:
        readable = vclib.check_path_access(var_70.repos, var_26,
                                           None, exam_rev)
      except vclib.ItemNotFound:
        readable = 0
      if not readable:
        found_unreadable = 1
        continue
         
    if var_70.var_30 == var_33:
      var_47 = { var_23: exam_rev }
    else:
      var_47 = { var_24: exam_rev, var_23: f.GetBranch() or None }  
    
    dir_href = var_70.get_url(var_52=var_39,
                               var_53=dirname, var_54=vclib.DIR,
                               var_47=var_47, escape=1)
    log_href = var_70.get_url(var_52=var_45,
                               var_53=var_53, var_54=vclib.FILE,
                               var_47=var_47, escape=1)
    diff_href = var_102 = var_103 = None
    if markup in var_12.options.allowed_views:
      var_102 = var_70.get_url(var_52=var_44,
                                  var_53=var_53, var_54=vclib.FILE,
                                  var_47=var_47, escape=1)
    if co in var_12.options.allowed_views:
      var_103 = var_70.get_url(var_52=var_27,
                                      var_53=var_53, var_54=vclib.FILE,
                                      var_47=var_47, escape=1)
    if change_type == Change:
      diff_href_params = var_47.copy()
      diff_href_params.update({
        r1: rev_prev,
        r2: var_60,
        diff_format: None
        })
      diff_href = var_70.get_url(var_52=var_40,
                                  var_53=var_53, var_54=vclib.FILE,
                                  var_47=diff_href_params, escape=1)
    var_98, var_110 = calculate_mime_type(var_70, var_26, exam_rev)
    var_108 = ezt.boolean(default_view(var_98, var_12) == var_44)

    
    plus = int(f.GetPlusCount())
    minus = int(f.GetMinusCount())
    plus_count = plus_count + plus
    minus_count = minus_count + minus
    
    num_allowed = num_allowed + 1
    if max_files and num_allowed > max_files:
      continue

    commit_files.append(_item(date=commit_time,
                              dir=var_70.var_11.escape(dirname),
                              file=var_70.var_11.escape(var_97),
                              author=var_70.var_11.escape(f.GetAuthor()),
                              var_60=var_60,
                              branch=f.GetBranch(),
                              plus=plus,
                              minus=minus,
                              var_32=change_type,
                              dir_href=dir_href,
                              log_href=log_href,
                              var_102=var_102,
                              var_103=var_103,
                              var_108=var_108,
                              diff_href=diff_href))

  
  
  if not len(commit_files):
    return None

  commit = _item(num_files=len(commit_files), files=commit_files,
                 plus=plus_count, minus=minus_count)
  commit.limited_files = ezt.boolean(num_allowed > len(commit_files))

  
  
  
  
  
  
  
  if found_unreadable:
    commit.log = None
    commit.short_log = None
  else:
    lf = LogFormatter(var_70, var_67)
    htmlize = (format != rss)
    commit.log = lf.get(maxlen=0, htmlize=htmlize)
    commit.short_log = lf.get(maxlen=var_12.options.short_log_len, htmlize=htmlize)
  commit.author = var_70.var_11.escape(author)
  commit.rss_date = make_rss_time_string(date, var_70.var_12)
  if var_70.var_30 == var_33:
    commit.var_60 = commit_rev
    commit.rss_url = %var_49://%var_49%var_49 % \
      (var_70.var_11.getenvHTTPS == on and https or http,
       var_70.var_11.getenvHTTP_HOST,
       var_70.get_url(var_52=view_revision,
                       var_47={var_24: commit.var_60},
                       escape=1))
  else:
    commit.var_60 = None
    commit.rss_url = None
  return commit

def query_backout(var_70, commits):
  var_89 = get_writeready_server_file(var_70, text/plain)
  if not commits:
    var_89.write()
    return
  var_89.write()
  for commit in commits:
    for fileinfo in commit.files:
      if var_70.var_30 == var_34:
        var_89.write(var_34 update -j %var_49 -j %var_49 %var_49/%var_49

                        % (fileinfo.var_60, prev_rev(fileinfo.var_60),
                           fileinfo.dir, fileinfo.file))
      elif var_70.var_30 == var_33:
        var_89.write(var_33 merge -r %var_49:%var_49 %var_49/%var_49

                        % (fileinfo.var_60, prev_rev(fileinfo.var_60),
                           fileinfo.dir, fileinfo.file))

def view_query(var_70):
  if not is_query_supported(var_70):
    raise debug.ViewVCException(Can not query project var_22 "%s" at "%s".
                                 % (var_70.var_56, var_70.var_53),
                                 403 Forbidden)

  var_12 = var_70.var_12

  
  validate_query_args(var_70)

  
  branch = var_70.query_dict.get('branch', '')
  branch_match = var_70.query_dict.get('branch_match', 'exact')
  dir = var_70.query_dict.get('dir', '')
  file = var_70.query_dict.get('file', '')
  file_match = var_70.query_dict.get('file_match', 'exact')
  who = var_70.query_dict.get('who', '')
  who_match = var_70.query_dict.get('who_match', 'exact')
  comment = var_70.query_dict.get('comment', '')
  comment_match = var_70.query_dict.get('comment_match', 'exact')
  querysort = var_70.query_dict.get('querysort', 'date')
  date = var_70.query_dict.get('date', 'hours')
  hours = var_70.query_dict.get('hours', '2')
  mindate = var_70.query_dict.get('mindate', '')
  maxdate = var_70.query_dict.get('maxdate', '')
  format = var_70.query_dict.getformat
  limit_changes = int(var_70.query_dict.get(limit_changes,
                                             var_12.options.limit_changes))

  match_types = {'exact': 1, 'like': 1, 'glob': 1, 'regex': 1, 'notregex': 1}
  sort_types = {'date': 1, 'author': 1, 'file': 1}
  date_types = {'hours': 1, 'day': 1, 'week': 1, 'month': 1, 'all': 1, 'explicit': 1}

  
  if not match_types.has_key(branch_match): branch_match = exact
  if not match_types.has_key(file_match): file_match = exact
  if not match_types.has_key(who_match): who_match = exact
  if not match_types.has_key(comment_match): comment_match = exact
  if not sort_types.has_key(querysort): querysort = date
  if not date_types.has_key(date): date = hours
  mindate = parse_date(mindate)
  maxdate = parse_date(maxdate)

  global cvsdb

  db = cvsdb.ConnectDatabaseReadOnly(var_12)
  repos_root, repos_dir = cvsdb.FindRepository(db, var_70.var_31)
  if not repos_root:
    raise debug.ViewVCException(
      The var_22 '%s' was not found in the commit database 
      % var_70.var_56)

  
  query = cvsdb.CreateCheckinQuery()
  query.SetRepository(repos_root)
  
  if branch_match == exact and branch == HEAD:
    query.SetBranch
  elif branch:
    query.SetBranch(branch, branch_match)
  if dir:
    for subdir in string.split(dir, ,):
      var_61 = (_path_join(repos_dir + var_70.var_26
                         + _path_parts(string.strip(subdir))))
      query.SetDirectory(var_61, exact)
      query.SetDirectory(%var_49/%% % cvsdb.EscapeLike(var_61), like)
  else:
    var_53 = _path_join(repos_dir + var_70.var_26)
    if var_53: 
      query.SetDirectory(var_53, exact)
      query.SetDirectory(%var_49/%% % cvsdb.EscapeLike(var_53), like)
  if file:
    query.SetFile(file, file_match)
  if who:
    query.SetAuthor(who, who_match)
  if comment:
    query.SetComment(comment, comment_match)
  query.SetSortMethod(querysort)
  if date == hours:
    query.SetFromDateHoursAgo(int(hours))
  elif date == day:
    query.SetFromDateDaysAgo1
  elif date == week:
    query.SetFromDateDaysAgo7
  elif date == month:
    query.SetFromDateDaysAgo31
  elif date == all:
    pass
  elif date == explicit:
    if mindate is not None:
      query.SetFromDateObject(mindate)
    if maxdate is not None:
      query.SetToDateObject(maxdate)

  
  
  if format == rss:
    query.SetLimit(var_12.cvsdb.rss_row_limit)
  else:
    query.SetLimit(var_12.cvsdb.row_limit)

  
  db.RunQuery(query)
  commit_list = query.GetCommitList()
  row_limit_reached = query.GetLimitReached()
  
  
  commits = []
  plus_count = 0
  minus_count = 0
  mod_time = -1
  if commit_list:
    files = []
    limited_files = 0
    current_desc = commit_list[0].GetDescriptionID()
    current_rev = commit_list[0].GetRevision()
    dir_strip = _path_join(repos_dir)

    for commit in commit_list:
      commit_desc = commit.GetDescriptionID()
      commit_rev = commit.GetRevision()

      
      if commit.GetTime() > mod_time:
        mod_time = commit.GetTime()
        
      
      
      if var_70.var_30 == var_34:
        if current_desc == commit_desc:
          files.append(commit)
          continue
      else:
        if current_rev == commit_rev:
          files.append(commit)
          continue

      
      commit_item = build_commit(var_70, files, limit_changes,
                                 dir_strip, format)
      if commit_item:
        
        plus_count = plus_count + commit_item.plus
        minus_count = minus_count + commit_item.minus
        commits.append(commit_item)

      files = [ commit ]
      limited_files = 0
      current_desc = commit_desc
      current_rev = commit_rev
      
    
    commit_item = build_commit(var_70, files, limit_changes,
                               dir_strip, format)
    if commit_item:
      
      plus_count = plus_count + commit_item.plus
      minus_count = minus_count + commit_item.minus
      commits.append(commit_item)
  
  
  
  show_branch = ezt.boolean(var_70.var_30 == var_34 and
                            (branch ==  or branch_match != exact))

  
  var_47 = var_70.query_dict.copy()
  var_47[format] = backout
  backout_href = var_70.get_url(var_47=var_47,
                                 escape=1)

  
  var_47 = var_70.query_dict.copy()
  var_47[limit_changes] = 0
  limit_changes_href = var_70.get_url(var_47=var_47, escape=1)

  
  if mod_time >= 0:
    if check_freshness(var_70, mod_time):
      return

  if format == backout:
    query_backout(var_70, commits)
    return

  var_88 = common_template_data(var_70)
  var_88.merge(ezt.TemplateData({
    sql: var_70.var_11.escape(db.CreateSQLQueryString(query)),
    english_query: english_query(var_70),
    queryform_href: var_70.get_url(var_52=view_queryform, escape=1),
    backout_href: backout_href,
    plus_count: plus_count,
    minus_count: minus_count,
    show_branch: show_branch,
    querysort: querysort,
    commits: commits,
    row_limit_reached : ezt.boolean(row_limit_reached),
    limit_changes: limit_changes,
    limit_changes_href: limit_changes_href,
    rss_link_href: var_70.get_url(var_52=view_query,
                                     var_47={'date': 'month'},
                                     escape=1,
                                     prefix=1),
    }))
  if format == rss:
    generate_page(var_70, rss, var_88, application/rss+xml)
  else:
    generate_page(var_70, query_results, var_88)

_views = {
  annotate:  var_41,
  co:        var_27,
  diff:      var_40,
  dir:       var_39,
  graph:     var_42,
  graphimg:  var_43,
  log:       var_45,
  markup:    var_44,
  patch:     view_patch,
  query:     view_query,
  queryform: view_queryform,
  var_24:  view_revision,
  roots:     var_37,
  tar:       var_38,
  redirect_pathrev: redirect_pathrev,
}

_view_codes = {}
for code, view in _views.var_91():
  _view_codes[view] = code

def list_roots(var_70):
  var_12 = var_70.var_12
  allroots = { }
  
  
  for var_22 in var_12.general.svn_roots.keys():
    auth = setup_authorizer(var_12, var_70.var_63, var_22)
    try:
      repos = vclib.var_33.SubversionRepository(var_22, var_12.general.svn_roots[var_22],
                                             auth, var_12.utilities,
                                             var_12.options.svn_config_dir)
      lastmod = None
      if var_12.options.show_roots_lastmod:
        try:
          repos.open()
          youngest_rev = repos.youngest
          date, author, msg, revprops, changes = repos.revinfo(youngest_rev)
          date_str = make_time_string(date, var_12)
          ago = html_time(var_70, date)
          lf = LogFormatter(var_70, msg)
          log = lf.get(maxlen=0, htmlize=1)
          short_log = lf.get(maxlen=var_12.options.short_log_len, htmlize=1)
          lastmod = _item(ago=ago, author=author, date=date_str, log=log,
                          short_log=short_log, var_60=str(youngest_rev))
        except:
          lastmod = None
    except vclib.ReposNotFound:
      continue
    allroots[var_22] = [var_12.general.svn_roots[var_22], var_33, lastmod]

  
  for var_22 in var_12.general.cvs_roots.keys():
    auth = setup_authorizer(var_12, var_70.var_63, var_22)
    try:
      vclib.ccvs.CVSRepository(var_22, var_12.general.cvs_roots[var_22], auth,
                               var_12.utilities, var_12.options.use_rcsparse)
    except vclib.ReposNotFound:
      continue
    allroots[var_22] = [var_12.general.cvs_roots[var_22], var_34, None]
    
  return allroots

def expand_root_parents(var_12):
  
  
  
  for pp in var_12.general.root_parents:
    pos = string.rfind(pp, :)
    if pos < 0:
      raise debug.ViewVCException(
        The var_61 "%s" in "root_parents" does not include a 
        repository var_32.  Expected "cvs" or "svn". % (pp))

    repo_type = string.strip(pp[pos+1:])
    pp = os.var_61.normpath(string.strip(pp[:pos]))

    if repo_type == var_34:
      roots = vclib.ccvs.expand_root_parent(pp)
      if var_12.options.hide_cvsroot and roots.has_keyCVSROOT:
        del roots[CVSROOT]
      var_12.general.cvs_roots.update(roots)
    elif repo_type == var_33:
      roots = vclib.var_33.expand_root_parent(pp)
      var_12.general.svn_roots.update(roots)
    else:
      raise debug.ViewVCException(
        The var_61 "%s" in "root_parents" has an unrecognized 
        repository var_32 ("%s").  Expected "cvs" or "svn".
        % (pp, repo_type))

def find_root_in_parents(var_12, var_56, var_30):
  

  
  if var_56 == CVSROOT and var_12.options.hide_cvsroot:
    return None
  
  for pp in var_12.general.root_parents:
    pos = string.rfind(pp, :)
    if pos < 0:
      continue
    repo_type = string.strip(pp[pos+1:])
    if repo_type != var_30:
      continue
    pp = os.var_61.normpath(string.strip(pp[:pos]))
    
    var_31 = None
    if var_30 == var_34:
      var_31 = vclib.ccvs.find_root_in_parent(pp, var_56)
    elif var_30 == var_33:
      var_31 = vclib.var_33.find_root_in_parent(pp, var_56)

    if var_31 is not None:
      return var_31
  return None

def locate_root(var_12, var_56):
  
  if var_12.general.cvs_roots.has_key(var_56):
    return var_34, var_12.general.cvs_roots[var_56]
  path_in_parent = find_root_in_parents(var_12, var_56, var_34)
  if path_in_parent:
    var_12.general.cvs_roots[var_56] = path_in_parent
    return var_34, path_in_parent
  if var_12.general.svn_roots.has_key(var_56):
    return var_33, var_12.general.svn_roots[var_56]
  path_in_parent = find_root_in_parents(var_12, var_56, var_33)
  if path_in_parent:
    var_12.general.svn_roots[var_56] = path_in_parent
    return var_33, path_in_parent
  return None, None
  
def load_config(pathname=None, var_11=None):
  
  
  debug.t_startload-config

  
  
  
  env_get = var_11 and var_11.getenv or os.environ.get
  env_pathname = (env_getVIEWVC_CONF_PATHNAME
                  or env_getVIEWCVS_CONF_PATHNAME)

  
  
  
  pathname = (env_pathname
              or pathname
              or os.var_61.join(os.var_61.dirname(os.var_61.dirname(__file__)),
                              viewvc.conf))

  
  var_12 = config.Config()
  var_12.set_defaults()
  var_12.load_config(pathname, env_getHTTP_HOST)

  
  
  
  if var_12.general.mime_types_files:
    files = var_12.general.mime_types_files[:]
    files.reverse()
    files = map(lambda x, y=pathname: os.var_61.join(os.var_61.dirname(y), x), files)
    mimetypes.init(files)
  
  debug.t_endload-config
  return var_12


def view_error(var_11, var_12):
  exc_dict = debug.GetExceptionData()
  status = exc_dict[status]
  if exc_dict[msg]:
    exc_dict[msg] = var_11.escape(exc_dict[msg])
  if exc_dict[stacktrace]:
    exc_dict[stacktrace] = var_11.escape(exc_dict[stacktrace])
  handled = 0
  
  
  try:
    if var_12 and not var_11.headerSent:
      var_11.header(status=status)
      var_82 = get_view_template(var_12, var_9)
      var_82.generate(var_11.file(), exc_dict)
      handled = 1
  except:
    pass

  
  
  if not handled:
    debug.PrintException(var_11, exc_dict)

def main(var_11, var_12):
  try:
    debug.t_startmain
    try:
      
      var_70 = Request(var_11, var_12)
      var_70.run_viewvc()
    except SystemExit, e:
      return
    except:
      view_error(var_11, var_12)

  finally:
    debug.t_endmain
    debug.t_dump(var_11.file())
    debug.DumpChildren(var_11)


class _item:
  def __init__(var_16, **kw):
    vars(var_16).update(kw)
